[2024-01-03T14:14:42.848+0000] {processor.py:157} INFO - Started process (PID=169) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:14:42.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:14:42.855+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:14:42.854+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:14:42.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:14:43.137+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:14:43.136+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:14:43.169+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:14:43.169+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2023-12-29T00:00:00+00:00, run_after=2023-12-30T00:00:00+00:00
[2024-01-03T14:14:43.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.348 seconds
[2024-01-03T14:15:13.757+0000] {processor.py:157} INFO - Started process (PID=216) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:15:13.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:15:13.770+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:15:13.769+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:15:13.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:15:13.871+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:15:13.870+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:15:13.906+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:15:13.906+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:15:13.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.181 seconds
[2024-01-03T14:15:44.600+0000] {processor.py:157} INFO - Started process (PID=248) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:15:44.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:15:44.603+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:15:44.603+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:15:44.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:15:44.666+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:15:44.666+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:15:44.691+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:15:44.691+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:15:44.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.147 seconds
[2024-01-03T14:16:15.007+0000] {processor.py:157} INFO - Started process (PID=308) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:16:15.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:16:15.009+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:16:15.009+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:16:15.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:16:15.099+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:16:15.099+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:16:15.124+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:16:15.124+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:16:15.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.136 seconds
[2024-01-03T14:16:45.229+0000] {processor.py:157} INFO - Started process (PID=367) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:16:45.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:16:45.232+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:16:45.232+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:16:45.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:16:45.306+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:16:45.306+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:16:45.331+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:16:45.331+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:16:45.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.123 seconds
[2024-01-03T14:17:15.816+0000] {processor.py:157} INFO - Started process (PID=399) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:17:15.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:17:15.820+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:17:15.819+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:17:15.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:17:15.894+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:17:15.894+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:17:15.935+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:17:15.935+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:17:15.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.145 seconds
[2024-01-03T14:17:46.490+0000] {processor.py:157} INFO - Started process (PID=431) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:17:46.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:17:46.493+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:17:46.493+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:17:46.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:17:46.594+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:17:46.594+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:17:46.619+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:17:46.619+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:17:47.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.538 seconds
[2024-01-03T14:18:17.929+0000] {processor.py:157} INFO - Started process (PID=468) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:18:17.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:18:17.932+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:18:17.932+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:18:17.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:18:18.020+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:18:18.020+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:18:18.047+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:18:18.046+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:18:18.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.138 seconds
[2024-01-03T14:18:37.305+0000] {processor.py:157} INFO - Started process (PID=485) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:18:37.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:18:37.309+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:18:37.308+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:18:37.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:18:37.385+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:18:37.384+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:18:37.406+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:18:37.405+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:18:37.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.122 seconds
[2024-01-03T14:19:08.183+0000] {processor.py:157} INFO - Started process (PID=517) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:19:08.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:19:08.186+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:19:08.185+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:19:08.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:19:08.244+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:19:08.244+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:19:08.263+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:19:08.263+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:19:08.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.099 seconds
[2024-01-03T14:19:33.931+0000] {processor.py:157} INFO - Started process (PID=545) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:19:33.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:19:33.936+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:19:33.935+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:19:33.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:19:34.010+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:19:34.009+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:19:34.031+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:19:34.031+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:19:34.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.126 seconds
[2024-01-03T14:20:04.589+0000] {processor.py:157} INFO - Started process (PID=577) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:20:04.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:20:04.593+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:20:04.592+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:20:04.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:20:04.664+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:20:04.664+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:20:04.688+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:20:04.688+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:20:05.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.505 seconds
[2024-01-03T14:20:35.738+0000] {processor.py:157} INFO - Started process (PID=609) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:20:35.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:20:35.741+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:20:35.741+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:20:35.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:20:35.833+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:20:35.833+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:20:36.138+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:20:36.138+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:20:36.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.420 seconds
[2024-01-03T14:21:06.346+0000] {processor.py:157} INFO - Started process (PID=641) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:21:06.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:21:06.350+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:21:06.350+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:21:06.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:21:06.443+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:21:06.443+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:21:06.468+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:21:06.467+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:21:06.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.143 seconds
[2024-01-03T14:21:36.893+0000] {processor.py:157} INFO - Started process (PID=673) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:21:36.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:21:36.896+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:21:36.896+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:21:36.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:21:36.964+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:21:36.964+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:21:37.000+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:21:37.000+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:21:37.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.136 seconds
[2024-01-03T14:22:07.428+0000] {processor.py:157} INFO - Started process (PID=704) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:22:07.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:22:07.432+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:22:07.431+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:22:07.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:22:07.527+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:22:07.526+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:22:07.550+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:22:07.549+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:22:07.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.143 seconds
[2024-01-03T14:22:38.089+0000] {processor.py:157} INFO - Started process (PID=736) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:22:38.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:22:38.093+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:22:38.093+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:22:38.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:22:38.183+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:22:38.183+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:22:38.208+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:22:38.208+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:22:38.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.156 seconds
[2024-01-03T14:23:08.648+0000] {processor.py:157} INFO - Started process (PID=768) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:23:08.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:23:08.652+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:23:08.651+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:23:08.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:23:08.733+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:23:08.733+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:23:08.760+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:23:08.760+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:23:09.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.446 seconds
[2024-01-03T14:23:39.248+0000] {processor.py:157} INFO - Started process (PID=800) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:23:39.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:23:39.252+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:23:39.251+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:23:39.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:23:39.322+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:23:39.321+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:23:39.370+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:23:39.370+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:23:39.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.145 seconds
[2024-01-03T14:24:10.001+0000] {processor.py:157} INFO - Started process (PID=832) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:24:10.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:24:10.004+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:24:10.003+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:24:10.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:24:10.086+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:24:10.085+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:24:10.112+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:24:10.112+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:24:10.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.132 seconds
[2024-01-03T14:24:40.762+0000] {processor.py:157} INFO - Started process (PID=864) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:24:40.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:24:40.766+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:24:40.765+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:24:40.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:24:40.837+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:24:40.837+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:24:40.861+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:24:40.861+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:24:40.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.118 seconds
[2024-01-03T14:25:11.399+0000] {processor.py:157} INFO - Started process (PID=896) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:25:11.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:25:11.410+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:25:11.406+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:25:11.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:25:11.487+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:25:11.486+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:25:11.507+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:25:11.507+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:25:11.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.136 seconds
[2024-01-03T14:25:42.015+0000] {processor.py:157} INFO - Started process (PID=928) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:25:42.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:25:42.022+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:25:42.021+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:25:42.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:25:42.092+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:25:42.092+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:25:42.117+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:25:42.117+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:25:42.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.506 seconds
[2024-01-03T14:26:13.070+0000] {processor.py:157} INFO - Started process (PID=960) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:26:13.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:26:13.077+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:26:13.076+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:26:13.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:26:13.166+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:26:13.166+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:26:13.527+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:26:13.527+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:26:13.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.486 seconds
[2024-01-03T14:26:44.607+0000] {processor.py:157} INFO - Started process (PID=992) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:26:44.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:26:44.611+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:26:44.611+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:26:44.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:26:44.688+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:26:44.688+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:26:44.869+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:26:44.868+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:26:45.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.545 seconds
[2024-01-03T14:27:15.614+0000] {processor.py:157} INFO - Started process (PID=1029) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:27:15.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:27:15.616+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:27:15.616+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:27:15.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:27:15.683+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:27:15.683+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:27:15.719+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:27:15.719+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:27:15.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.126 seconds
[2024-01-03T14:27:46.114+0000] {processor.py:157} INFO - Started process (PID=1056) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:27:46.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:27:46.124+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:27:46.122+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:27:46.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:27:46.219+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:27:46.219+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:27:46.242+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:27:46.242+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:27:46.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.164 seconds
[2024-01-03T14:28:17.057+0000] {processor.py:157} INFO - Started process (PID=1088) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:28:17.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:28:17.062+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:28:17.061+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:28:17.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:28:17.161+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:28:17.161+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:28:17.208+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:28:17.207+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:28:17.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.192 seconds
[2024-01-03T14:28:47.842+0000] {processor.py:157} INFO - Started process (PID=1120) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:28:47.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:28:47.847+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:28:47.846+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:28:47.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:28:47.950+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:28:47.950+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:28:48.487+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:28:48.487+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:28:48.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.680 seconds
[2024-01-03T14:29:19.053+0000] {processor.py:157} INFO - Started process (PID=1157) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:29:19.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:29:19.059+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:29:19.059+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:29:19.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:29:19.135+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:29:19.134+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:29:19.163+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:29:19.163+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:29:19.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.135 seconds
[2024-01-03T14:29:49.653+0000] {processor.py:157} INFO - Started process (PID=1189) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:29:49.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:29:49.657+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:29:49.656+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:29:49.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:29:49.715+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:29:49.715+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:29:49.745+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:29:49.745+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:29:49.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.112 seconds
[2024-01-03T14:30:20.267+0000] {processor.py:157} INFO - Started process (PID=1221) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:30:20.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:30:20.270+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:30:20.269+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:30:20.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:30:20.326+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:30:20.326+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:30:20.346+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:30:20.346+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:30:20.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.098 seconds
[2024-01-03T14:30:50.965+0000] {processor.py:157} INFO - Started process (PID=1253) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:30:50.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:30:50.974+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:30:50.973+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:30:51.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:30:51.202+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:30:51.202+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:30:51.547+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:30:51.545+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:30:51.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.921 seconds
[2024-01-03T14:31:22.612+0000] {processor.py:157} INFO - Started process (PID=1290) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:31:22.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:31:22.615+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:31:22.615+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:31:22.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:31:22.697+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:31:22.697+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:31:23.158+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:31:23.157+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:31:23.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.568 seconds
[2024-01-03T14:31:53.333+0000] {processor.py:157} INFO - Started process (PID=1322) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:31:53.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:31:53.337+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:31:53.336+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:31:53.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:31:53.426+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:31:53.425+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:31:53.451+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:31:53.450+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:31:53.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.139 seconds
[2024-01-03T14:32:23.876+0000] {processor.py:157} INFO - Started process (PID=1354) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:32:23.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:32:23.879+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:32:23.879+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:32:23.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:32:23.950+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:32:23.950+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:32:23.979+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:32:23.978+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:32:23.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.125 seconds
[2024-01-03T14:32:54.482+0000] {processor.py:157} INFO - Started process (PID=1386) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:32:54.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:32:54.485+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:32:54.485+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:32:54.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:32:54.556+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:32:54.556+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:32:54.583+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:32:54.583+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:32:54.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.124 seconds
[2024-01-03T14:33:25.103+0000] {processor.py:157} INFO - Started process (PID=1418) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:33:25.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:33:25.106+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:33:25.106+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:33:25.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:33:25.171+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:33:25.170+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:33:25.197+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:33:25.197+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:33:25.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.117 seconds
[2024-01-03T14:33:55.693+0000] {processor.py:157} INFO - Started process (PID=1450) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:33:55.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:33:55.696+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:33:55.695+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:33:55.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:33:55.756+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:33:55.755+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:33:55.781+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:33:55.780+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:33:56.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.433 seconds
[2024-01-03T14:34:26.304+0000] {processor.py:157} INFO - Started process (PID=1482) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:34:26.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:34:26.307+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:34:26.307+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:34:26.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:34:26.392+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:34:26.391+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:34:26.949+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:34:26.948+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:34:27.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.714 seconds
[2024-01-03T14:34:57.994+0000] {processor.py:157} INFO - Started process (PID=1514) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:34:58.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:34:58.003+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:34:58.002+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:34:58.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:34:58.085+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:34:58.085+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:34:58.118+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:34:58.118+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:34:58.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.158 seconds
[2024-01-03T14:35:28.774+0000] {processor.py:157} INFO - Started process (PID=1546) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:35:28.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:35:28.777+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:35:28.777+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:35:28.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:35:28.866+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:35:28.865+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:35:28.896+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:35:28.896+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:35:28.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.147 seconds
[2024-01-03T14:35:59.559+0000] {processor.py:157} INFO - Started process (PID=1578) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:35:59.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:35:59.562+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:35:59.562+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:35:59.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:35:59.662+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:35:59.661+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:35:59.695+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:35:59.695+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:35:59.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.166 seconds
[2024-01-03T14:36:30.559+0000] {processor.py:157} INFO - Started process (PID=1615) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:36:30.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:36:30.569+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:36:30.569+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:36:30.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:36:30.918+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:36:30.917+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:36:30.964+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:36:30.964+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:36:31.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 1.006 seconds
[2024-01-03T14:37:02.140+0000] {processor.py:157} INFO - Started process (PID=1653) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:37:02.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:37:02.147+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:37:02.146+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:37:02.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:37:02.255+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:37:02.255+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:37:03.029+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:37:03.026+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:37:03.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.950 seconds
[2024-01-03T14:37:33.994+0000] {processor.py:157} INFO - Started process (PID=1685) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:37:33.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:37:33.998+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:37:33.997+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:37:34.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:37:34.075+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:37:34.075+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:37:34.101+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:37:34.101+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:37:34.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.131 seconds
[2024-01-03T14:38:04.430+0000] {processor.py:157} INFO - Started process (PID=1717) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:38:04.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:38:04.438+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:38:04.437+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:38:04.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:38:04.573+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:38:04.573+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:38:04.643+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:38:04.643+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:38:04.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.281 seconds
[2024-01-03T14:38:35.158+0000] {processor.py:157} INFO - Started process (PID=1749) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:38:35.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:38:35.162+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:38:35.162+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:38:35.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:38:35.342+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:38:35.341+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:38:35.390+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:38:35.390+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:38:35.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.259 seconds
[2024-01-03T14:39:05.643+0000] {processor.py:157} INFO - Started process (PID=1781) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:39:05.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:39:05.647+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:39:05.646+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:39:05.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:39:05.735+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:39:05.735+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:39:05.760+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:39:05.760+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:39:05.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.140 seconds
[2024-01-03T14:39:36.177+0000] {processor.py:157} INFO - Started process (PID=1813) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:39:36.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:39:36.180+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:39:36.179+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:39:36.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:39:36.263+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:39:36.263+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:39:36.779+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:39:36.778+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:39:36.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.624 seconds
[2024-01-03T14:40:07.551+0000] {processor.py:157} INFO - Started process (PID=1845) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:40:07.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:40:07.571+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:40:07.570+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:40:07.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:40:07.662+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:40:07.662+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:40:08.010+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:40:08.010+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:40:08.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.484 seconds
[2024-01-03T14:40:38.937+0000] {processor.py:157} INFO - Started process (PID=1877) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:40:38.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:40:38.941+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:40:38.940+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:40:38.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:40:39.037+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:40:39.037+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:40:39.066+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:40:39.066+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:40:39.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.153 seconds
[2024-01-03T14:41:09.694+0000] {processor.py:157} INFO - Started process (PID=1909) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:41:09.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:41:09.697+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:41:09.697+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:41:09.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:41:09.802+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:41:09.802+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:41:09.832+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:41:09.832+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:41:09.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.163 seconds
[2024-01-03T14:41:40.755+0000] {processor.py:157} INFO - Started process (PID=1941) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:41:40.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:41:40.767+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:41:40.764+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:41:40.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:41:40.875+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:41:40.874+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:41:40.904+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:41:40.903+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:41:40.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.190 seconds
[2024-01-03T14:42:11.105+0000] {processor.py:157} INFO - Started process (PID=1973) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:42:11.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:42:11.109+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:42:11.108+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:42:11.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:42:11.180+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:42:11.180+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:42:11.206+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:42:11.206+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:42:11.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.462 seconds
[2024-01-03T14:42:41.975+0000] {processor.py:157} INFO - Started process (PID=2005) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:42:41.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:42:41.978+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:42:41.978+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:42:42.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:42:42.042+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:42:42.042+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:42:42.380+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:42:42.379+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:42:42.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.422 seconds
[2024-01-03T14:43:12.921+0000] {processor.py:157} INFO - Started process (PID=2037) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:43:12.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:43:12.924+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:43:12.923+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:43:12.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:43:13.000+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:43:13.000+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:43:13.027+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:43:13.027+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:43:13.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.126 seconds
[2024-01-03T14:43:43.515+0000] {processor.py:157} INFO - Started process (PID=2069) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:43:43.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:43:43.524+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:43:43.521+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:43:43.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:43:43.609+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:43:43.609+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:43:43.636+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:43:43.635+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:43:43.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.158 seconds
[2024-01-03T14:44:14.375+0000] {processor.py:157} INFO - Started process (PID=2101) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:44:14.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:44:14.379+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:44:14.379+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:44:14.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:44:14.468+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:44:14.468+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:44:14.494+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:44:14.494+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:44:14.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.140 seconds
[2024-01-03T14:44:45.434+0000] {processor.py:157} INFO - Started process (PID=2133) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:44:45.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:44:45.450+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:44:45.449+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:44:45.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:44:45.525+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:44:45.525+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:44:45.551+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:44:45.551+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:44:45.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.465 seconds
[2024-01-03T14:45:16.872+0000] {processor.py:157} INFO - Started process (PID=2165) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:45:16.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:45:16.880+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:45:16.879+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:45:16.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:45:16.988+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:45:16.987+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:45:17.419+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:45:17.419+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:45:17.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.586 seconds
[2024-01-03T14:45:47.968+0000] {processor.py:157} INFO - Started process (PID=2197) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:45:47.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:45:47.973+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:45:47.972+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:45:48.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:45:48.041+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:45:48.041+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:45:48.372+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:45:48.372+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:45:48.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.427 seconds
[2024-01-03T14:46:19.051+0000] {processor.py:157} INFO - Started process (PID=2234) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:46:19.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:46:19.064+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:46:19.063+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:46:19.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:46:20.050+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:46:20.045+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:46:20.186+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:46:20.186+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:46:20.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 1.205 seconds
[2024-01-03T14:46:51.354+0000] {processor.py:157} INFO - Started process (PID=2266) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:46:51.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:46:51.357+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:46:51.356+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:46:51.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:46:51.517+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:46:51.517+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:46:51.566+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:46:51.565+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:46:51.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.237 seconds
[2024-01-03T14:47:22.442+0000] {processor.py:157} INFO - Started process (PID=2299) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:47:22.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:47:22.446+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:47:22.445+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:47:22.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:47:22.572+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:47:22.571+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:47:22.597+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:47:22.597+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:47:22.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.178 seconds
[2024-01-03T14:47:53.460+0000] {processor.py:157} INFO - Started process (PID=2331) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:47:53.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:47:53.466+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:47:53.465+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:47:53.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:47:53.539+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:47:53.539+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:47:53.563+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:47:53.563+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:47:54.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.608 seconds
[2024-01-03T14:48:24.758+0000] {processor.py:157} INFO - Started process (PID=2363) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:48:24.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:48:24.761+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:48:24.761+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:48:24.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:48:24.839+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:48:24.838+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:48:25.333+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:48:25.332+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:48:25.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.596 seconds
[2024-01-03T14:48:56.418+0000] {processor.py:157} INFO - Started process (PID=2395) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:48:56.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:48:56.427+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:48:56.425+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:48:56.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:48:56.637+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:48:56.637+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:48:56.720+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:48:56.719+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:48:56.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.392 seconds
[2024-01-03T14:49:27.108+0000] {processor.py:157} INFO - Started process (PID=2427) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:49:27.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:49:27.113+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:49:27.112+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:49:27.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:49:27.203+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:49:27.203+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:49:27.233+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:49:27.233+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:49:27.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.153 seconds
[2024-01-03T14:49:58.156+0000] {processor.py:157} INFO - Started process (PID=2459) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:49:58.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:49:58.163+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:49:58.158+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:49:58.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:49:58.246+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:49:58.246+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:49:58.289+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:49:58.289+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:49:58.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.156 seconds
[2024-01-03T14:50:28.609+0000] {processor.py:157} INFO - Started process (PID=2491) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:50:28.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:50:28.614+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:50:28.613+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:50:28.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:50:28.709+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:50:28.708+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:50:28.755+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:50:28.753+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:50:29.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.622 seconds
[2024-01-03T14:51:00.077+0000] {processor.py:157} INFO - Started process (PID=2523) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:51:00.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:51:00.083+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:51:00.082+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:51:00.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:51:00.277+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:51:00.276+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:51:00.722+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:51:00.721+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:51:00.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.673 seconds
[2024-01-03T14:51:31.385+0000] {processor.py:157} INFO - Started process (PID=2555) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:51:31.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:51:31.400+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:51:31.399+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:51:31.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:51:31.594+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:51:31.594+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:51:32.517+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:51:32.517+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:51:32.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 1.191 seconds
[2024-01-03T14:52:03.799+0000] {processor.py:157} INFO - Started process (PID=2587) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:52:03.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:52:03.806+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:52:03.804+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:52:03.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:52:04.380+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:52:04.379+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:52:04.513+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:52:04.512+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:52:04.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.785 seconds
[2024-01-03T14:52:35.427+0000] {processor.py:157} INFO - Started process (PID=2619) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:52:35.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:52:35.430+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:52:35.430+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:52:35.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:52:35.519+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:52:35.519+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:52:35.551+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:52:35.551+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:52:35.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.160 seconds
[2024-01-03T14:53:06.217+0000] {processor.py:157} INFO - Started process (PID=2659) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:53:06.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:53:06.220+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:53:06.220+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:53:06.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:53:06.324+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:53:06.324+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:53:06.363+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:53:06.363+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:53:06.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.173 seconds
[2024-01-03T14:53:36.905+0000] {processor.py:157} INFO - Started process (PID=2692) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:53:36.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:53:36.909+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:53:36.908+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:53:36.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:53:37.002+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:53:37.002+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:53:37.601+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:53:37.601+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:53:37.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.725 seconds
[2024-01-03T14:54:08.282+0000] {processor.py:157} INFO - Started process (PID=2724) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:54:08.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:54:08.286+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:54:08.285+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:54:08.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:54:08.377+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:54:08.376+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:54:08.736+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:54:08.736+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:54:08.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.474 seconds
[2024-01-03T14:54:39.090+0000] {processor.py:157} INFO - Started process (PID=2756) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:54:39.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:54:39.093+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:54:39.092+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:54:39.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:54:39.178+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:54:39.178+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:54:39.200+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:54:39.200+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:54:39.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.130 seconds
[2024-01-03T14:55:09.900+0000] {processor.py:157} INFO - Started process (PID=2788) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:55:09.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:55:09.912+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:55:09.910+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:55:09.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:55:10.001+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:55:10.000+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:55:10.025+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:55:10.025+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:55:10.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.166 seconds
[2024-01-03T14:55:40.552+0000] {processor.py:157} INFO - Started process (PID=2820) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:55:40.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:55:40.557+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:55:40.556+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:55:40.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:55:40.626+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:55:40.626+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:55:40.653+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:55:40.653+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:55:40.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.140 seconds
[2024-01-03T14:56:11.380+0000] {processor.py:157} INFO - Started process (PID=2852) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:56:11.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:56:11.385+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:56:11.384+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:56:11.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:56:11.455+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:56:11.454+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:56:11.491+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:56:11.491+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:56:11.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.436 seconds
[2024-01-03T14:56:41.949+0000] {processor.py:157} INFO - Started process (PID=2884) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:56:41.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:56:41.952+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:56:41.952+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:56:41.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:56:42.030+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:56:42.030+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:56:42.396+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:56:42.396+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:56:42.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.474 seconds
[2024-01-03T14:57:12.650+0000] {processor.py:157} INFO - Started process (PID=2916) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:57:12.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:57:12.655+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:57:12.654+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:57:12.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:57:12.835+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:57:12.835+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:57:13.391+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:57:13.391+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:57:13.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.775 seconds
[2024-01-03T14:57:44.102+0000] {processor.py:157} INFO - Started process (PID=2948) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:57:44.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:57:44.106+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:57:44.105+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:57:44.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:57:44.184+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:57:44.184+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:57:44.206+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:57:44.206+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:57:44.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.124 seconds
[2024-01-03T14:58:14.901+0000] {processor.py:157} INFO - Started process (PID=2980) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:58:14.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:58:14.904+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:58:14.903+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:58:14.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:58:14.959+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:58:14.958+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:58:14.983+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:58:14.983+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:58:14.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.100 seconds
[2024-01-03T14:58:45.572+0000] {processor.py:157} INFO - Started process (PID=3012) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:58:45.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:58:45.575+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:58:45.574+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:58:45.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:58:45.650+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:58:45.649+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:58:45.686+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:58:45.686+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:58:46.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.942 seconds
[2024-01-03T14:59:17.238+0000] {processor.py:157} INFO - Started process (PID=3044) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:59:17.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:59:17.241+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:59:17.241+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:59:17.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:59:17.548+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:59:17.546+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:59:21.696+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:59:21.695+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:59:21.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 4.507 seconds
[2024-01-03T14:59:52.095+0000] {processor.py:157} INFO - Started process (PID=3076) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:59:52.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T14:59:52.100+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:59:52.099+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:59:52.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T14:59:52.210+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:59:52.210+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T14:59:52.606+0000] {logging_mixin.py:154} INFO - [2024-01-03T14:59:52.606+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T14:59:52.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.534 seconds
[2024-01-03T15:00:23.383+0000] {processor.py:157} INFO - Started process (PID=3108) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:00:23.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:00:23.388+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:00:23.387+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:00:23.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:00:23.485+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:00:23.485+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:00:23.514+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:00:23.514+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:00:23.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.161 seconds
[2024-01-03T15:00:54.255+0000] {processor.py:157} INFO - Started process (PID=3140) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:00:54.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:00:54.258+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:00:54.258+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:00:54.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:00:54.386+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:00:54.386+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:00:54.427+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:00:54.426+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:00:54.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.195 seconds
[2024-01-03T15:01:24.903+0000] {processor.py:157} INFO - Started process (PID=3172) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:01:24.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:01:24.907+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:01:24.906+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:01:24.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:01:24.999+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:01:24.999+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:01:25.026+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:01:25.025+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:01:25.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.148 seconds
[2024-01-03T15:01:55.467+0000] {processor.py:157} INFO - Started process (PID=3204) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:01:55.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:01:55.471+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:01:55.471+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:01:55.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:01:55.544+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:01:55.544+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:01:55.571+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:01:55.570+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:01:55.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.526 seconds
[2024-01-03T15:02:26.602+0000] {processor.py:157} INFO - Started process (PID=3236) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:02:26.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:02:26.607+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:02:26.606+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:02:26.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:02:26.679+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:02:26.679+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:02:27.257+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:02:27.257+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:02:27.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.692 seconds
[2024-01-03T15:02:57.369+0000] {processor.py:157} INFO - Started process (PID=3268) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:02:57.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:02:57.374+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:02:57.373+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:02:57.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:02:57.448+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:02:57.448+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:02:57.825+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:02:57.824+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:02:57.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.480 seconds
[2024-01-03T15:03:28.510+0000] {processor.py:157} INFO - Started process (PID=3300) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:03:28.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:03:28.514+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:03:28.513+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:03:28.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:03:28.600+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:03:28.600+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:03:28.622+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:03:28.622+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:03:28.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.132 seconds
[2024-01-03T15:03:59.279+0000] {processor.py:157} INFO - Started process (PID=3332) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:03:59.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:03:59.286+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:03:59.284+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:03:59.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:03:59.496+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:03:59.496+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:03:59.552+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:03:59.551+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:03:59.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.362 seconds
[2024-01-03T15:04:30.248+0000] {processor.py:157} INFO - Started process (PID=3364) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:04:30.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:04:30.252+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:04:30.251+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:04:30.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:04:30.322+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:04:30.322+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:04:30.347+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:04:30.347+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:04:30.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.465 seconds
[2024-01-03T15:05:00.979+0000] {processor.py:157} INFO - Started process (PID=3396) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:05:00.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:05:00.983+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:05:00.982+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:05:01.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:05:01.066+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:05:01.065+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:05:01.394+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:05:01.394+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:05:01.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.444 seconds
[2024-01-03T15:05:31.973+0000] {processor.py:157} INFO - Started process (PID=3428) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:05:31.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:05:31.977+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:05:31.976+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:05:32.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:05:32.084+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:05:32.084+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:05:32.404+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:05:32.404+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:05:32.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.453 seconds
[2024-01-03T15:06:02.627+0000] {processor.py:157} INFO - Started process (PID=3460) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:06:02.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:06:02.631+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:06:02.630+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:06:02.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:06:02.730+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:06:02.730+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:06:02.754+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:06:02.754+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:06:02.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.148 seconds
[2024-01-03T15:06:33.585+0000] {processor.py:157} INFO - Started process (PID=3492) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:06:33.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:06:33.590+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:06:33.590+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:06:33.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:06:33.665+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:06:33.665+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:06:33.696+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:06:33.696+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:06:33.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.157 seconds
[2024-01-03T15:07:04.335+0000] {processor.py:157} INFO - Started process (PID=3524) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:07:04.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:07:04.339+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:07:04.338+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:07:04.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:07:04.413+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:07:04.413+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:07:04.439+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:07:04.439+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:07:04.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.128 seconds
[2024-01-03T15:07:34.951+0000] {processor.py:157} INFO - Started process (PID=3556) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:07:34.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:07:34.960+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:07:34.959+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:07:35.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:07:35.040+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:07:35.040+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:07:35.349+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:07:35.349+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:07:35.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.423 seconds
[2024-01-03T15:08:05.779+0000] {processor.py:157} INFO - Started process (PID=3588) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:08:05.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:08:05.783+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:08:05.782+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:08:05.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:08:05.884+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:08:05.884+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:08:06.357+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:08:06.357+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:08:06.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.598 seconds
[2024-01-03T15:08:37.113+0000] {processor.py:157} INFO - Started process (PID=3620) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:08:37.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:08:37.117+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:08:37.117+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:08:37.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:08:37.542+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:08:37.542+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:08:37.562+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:08:37.561+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:08:37.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.475 seconds
[2024-01-03T15:09:08.386+0000] {processor.py:157} INFO - Started process (PID=3662) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:09:08.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:09:08.388+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:09:08.388+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:09:08.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:09:08.457+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:09:08.457+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:09:08.487+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:09:08.487+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:09:08.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.140 seconds
[2024-01-03T15:09:38.933+0000] {processor.py:157} INFO - Started process (PID=3694) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:09:38.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:09:38.936+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:09:38.935+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:09:38.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:09:38.991+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:09:38.991+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:09:39.013+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:09:39.013+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:09:39.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.102 seconds
[2024-01-03T15:10:09.357+0000] {processor.py:157} INFO - Started process (PID=3726) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:10:09.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:10:09.361+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:10:09.360+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:10:09.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:10:09.592+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:10:09.591+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:10:09.669+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:10:09.668+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:10:11.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 1.667 seconds
[2024-01-03T15:10:41.621+0000] {processor.py:157} INFO - Started process (PID=3765) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:10:41.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:10:41.623+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:10:41.623+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:10:41.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:10:41.676+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:10:41.676+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:10:42.007+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:10:42.006+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:10:42.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.407 seconds
[2024-01-03T15:11:12.174+0000] {processor.py:157} INFO - Started process (PID=3797) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:11:12.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:11:12.177+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:11:12.176+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:11:12.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:11:12.232+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:11:12.232+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:11:12.597+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:11:12.597+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:11:12.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.453 seconds
[2024-01-03T15:11:42.929+0000] {processor.py:157} INFO - Started process (PID=3829) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:11:42.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:11:42.933+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:11:42.932+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:11:42.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:11:43.010+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:11:43.010+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:11:43.031+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:11:43.031+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:11:43.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.124 seconds
[2024-01-03T15:12:13.840+0000] {processor.py:157} INFO - Started process (PID=3861) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:12:13.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:12:13.891+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:12:13.862+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:12:13.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:12:14.026+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:12:14.026+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:12:14.060+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:12:14.060+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:12:14.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.425 seconds
[2024-01-03T15:12:44.396+0000] {processor.py:157} INFO - Started process (PID=3895) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:12:44.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:12:44.402+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:12:44.401+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:12:44.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:12:44.490+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:12:44.490+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:12:44.526+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:12:44.525+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:12:45.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.700 seconds
[2024-01-03T15:13:16.009+0000] {processor.py:157} INFO - Started process (PID=3929) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:13:16.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:13:16.019+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:13:16.017+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:13:16.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:13:16.119+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:13:16.119+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:13:16.562+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:13:16.562+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:13:16.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.591 seconds
[2024-01-03T15:13:47.250+0000] {processor.py:157} INFO - Started process (PID=3961) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:13:47.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:13:47.266+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:13:47.265+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:13:47.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:13:47.351+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:13:47.351+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:13:47.751+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:13:47.750+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:13:47.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.528 seconds
[2024-01-03T15:14:18.453+0000] {processor.py:157} INFO - Started process (PID=3993) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:14:18.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:14:18.456+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:14:18.456+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:14:18.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:14:18.967+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:14:18.967+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:14:18.988+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:14:18.988+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:14:19.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.558 seconds
[2024-01-03T15:14:49.770+0000] {processor.py:157} INFO - Started process (PID=4025) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:14:49.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:14:49.774+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:14:49.774+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:14:49.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:14:49.874+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:14:49.874+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:14:49.902+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:14:49.902+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:14:49.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.170 seconds
[2024-01-03T15:15:20.429+0000] {processor.py:157} INFO - Started process (PID=4057) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:15:20.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:15:20.433+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:15:20.432+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:15:20.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:15:20.525+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:15:20.524+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:15:20.549+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:15:20.549+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:15:20.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.143 seconds
[2024-01-03T15:15:51.276+0000] {processor.py:157} INFO - Started process (PID=4089) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:15:51.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:15:51.280+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:15:51.279+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:15:51.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:15:51.379+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:15:51.379+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:15:51.417+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:15:51.416+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:15:51.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.559 seconds
[2024-01-03T15:16:22.125+0000] {processor.py:157} INFO - Started process (PID=4121) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:16:22.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:16:22.132+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:16:22.131+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:16:22.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:16:22.283+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:16:22.283+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:16:22.667+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:16:22.667+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:16:22.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.577 seconds
[2024-01-03T15:16:52.818+0000] {processor.py:157} INFO - Started process (PID=4153) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:16:52.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:16:52.823+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:16:52.822+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:16:52.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:16:53.318+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:16:53.318+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:16:53.338+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:16:53.338+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:16:53.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.541 seconds
[2024-01-03T15:17:24.109+0000] {processor.py:157} INFO - Started process (PID=4185) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:17:24.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:17:24.113+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:17:24.112+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:17:24.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:17:25.417+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:17:25.417+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:17:25.441+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:17:25.441+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:17:25.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 1.355 seconds
[2024-01-03T15:17:56.527+0000] {processor.py:157} INFO - Started process (PID=4217) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:17:56.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:17:56.535+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:17:56.534+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:17:56.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:17:56.638+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:17:56.638+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:17:56.682+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:17:56.682+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:17:56.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.183 seconds
[2024-01-03T15:18:27.139+0000] {processor.py:157} INFO - Started process (PID=4249) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:18:27.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:18:27.149+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:18:27.148+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:18:27.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:18:27.214+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:18:27.214+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:18:27.245+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:18:27.245+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:18:27.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.642 seconds
[2024-01-03T15:18:58.425+0000] {processor.py:157} INFO - Started process (PID=4281) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:18:58.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:18:58.438+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:18:58.437+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:18:58.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:18:58.512+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:18:58.511+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:18:58.937+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:18:58.937+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:18:58.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.547 seconds
[2024-01-03T15:19:29.059+0000] {processor.py:157} INFO - Started process (PID=4313) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:19:29.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:19:29.064+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:19:29.063+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:19:29.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:19:29.162+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:19:29.162+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:19:29.614+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:19:29.614+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:19:29.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.594 seconds
[2024-01-03T15:19:39.954+0000] {processor.py:157} INFO - Started process (PID=4323) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:19:39.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:19:39.958+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:19:39.957+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:19:40.004+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:19:40.001+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:19:40.005+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:19:40.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.259 seconds
[2024-01-03T15:19:43.093+0000] {processor.py:157} INFO - Started process (PID=4328) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:19:43.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:19:43.097+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:19:43.096+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:19:43.153+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:19:43.151+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:19:43.153+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:19:43.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.116 seconds
[2024-01-03T15:20:13.992+0000] {processor.py:157} INFO - Started process (PID=4360) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:20:13.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:20:13.995+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:20:13.995+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:20:14.041+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:20:14.039+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:20:14.041+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:20:14.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.084 seconds
[2024-01-03T15:20:44.868+0000] {processor.py:157} INFO - Started process (PID=4392) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:20:44.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:20:44.873+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:20:44.872+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:20:44.905+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:20:44.903+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:20:44.906+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:20:44.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.078 seconds
[2024-01-03T15:21:15.597+0000] {processor.py:157} INFO - Started process (PID=4424) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:21:15.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:21:15.601+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:21:15.601+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:21:15.632+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:21:15.630+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:21:15.632+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:21:15.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.070 seconds
[2024-01-03T15:21:46.409+0000] {processor.py:157} INFO - Started process (PID=4463) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:21:46.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:21:46.412+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:21:46.412+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:21:46.443+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:21:46.441+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:21:46.444+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:21:46.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.085 seconds
[2024-01-03T15:22:17.194+0000] {processor.py:157} INFO - Started process (PID=4495) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:22:17.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:22:17.198+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:22:17.197+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:22:17.225+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:22:17.223+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:22:17.226+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:22:17.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.080 seconds
[2024-01-03T15:22:47.724+0000] {processor.py:157} INFO - Started process (PID=4527) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:22:47.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:22:47.727+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:22:47.727+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:22:47.755+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:22:47.753+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:22:47.755+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:22:47.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.057 seconds
[2024-01-03T15:23:18.089+0000] {processor.py:157} INFO - Started process (PID=4559) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:23:18.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:23:18.093+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:23:18.092+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:23:18.132+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:23:18.130+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:23:18.133+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:23:18.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.078 seconds
[2024-01-03T15:23:48.760+0000] {processor.py:157} INFO - Started process (PID=4590) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:23:48.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:23:48.774+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:23:48.772+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:23:48.991+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:23:48.983+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:23:48.993+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:23:49.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.448 seconds
[2024-01-03T15:24:20.145+0000] {processor.py:157} INFO - Started process (PID=4623) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:24:20.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:24:20.148+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:24:20.148+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:24:20.177+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:24:20.175+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:24:20.178+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:24:20.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.066 seconds
[2024-01-03T15:24:51.045+0000] {processor.py:157} INFO - Started process (PID=4655) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:24:51.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:24:51.049+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:24:51.048+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:24:51.110+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:24:51.108+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:24:51.110+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:24:51.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.101 seconds
[2024-01-03T15:25:21.634+0000] {processor.py:157} INFO - Started process (PID=4686) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:25:21.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:25:21.639+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:25:21.638+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:25:21.681+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:25:21.679+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:25:21.681+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:25:21.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.081 seconds
[2024-01-03T15:25:52.129+0000] {processor.py:157} INFO - Started process (PID=4718) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:25:52.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:25:52.132+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:25:52.132+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:25:52.173+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:25:52.165+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:25:52.174+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:25:52.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.082 seconds
[2024-01-03T15:26:22.704+0000] {processor.py:157} INFO - Started process (PID=4750) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:26:22.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:26:22.707+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:26:22.707+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:26:22.736+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:26:22.734+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:26:22.737+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:26:22.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.076 seconds
[2024-01-03T15:26:53.436+0000] {processor.py:157} INFO - Started process (PID=4782) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:26:53.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:26:53.440+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:26:53.439+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:26:53.471+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:26:53.469+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:26:53.472+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:26:53.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.078 seconds
[2024-01-03T15:27:24.398+0000] {processor.py:157} INFO - Started process (PID=4814) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:27:24.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:27:24.412+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:27:24.409+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:27:24.490+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:27:24.488+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:27:24.492+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:27:24.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.150 seconds
[2024-01-03T15:27:55.143+0000] {processor.py:157} INFO - Started process (PID=4846) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:27:55.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:27:55.148+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:27:55.147+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:27:55.179+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:27:55.177+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:27:55.179+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:27:55.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.094 seconds
[2024-01-03T15:28:25.796+0000] {processor.py:157} INFO - Started process (PID=4878) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:28:25.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:28:25.801+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:28:25.800+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:28:25.831+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:28:25.830+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:28:25.832+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:28:25.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.081 seconds
[2024-01-03T15:28:56.437+0000] {processor.py:157} INFO - Started process (PID=4910) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:28:56.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:28:56.441+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:28:56.440+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:28:56.471+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:28:56.470+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:28:56.472+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:28:56.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.069 seconds
[2024-01-03T15:29:26.921+0000] {processor.py:157} INFO - Started process (PID=4942) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:29:26.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:29:26.924+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:29:26.924+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:29:26.955+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:29:26.953+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:29:26.955+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:29:26.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.070 seconds
[2024-01-03T15:29:57.686+0000] {processor.py:157} INFO - Started process (PID=4974) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:29:57.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:29:57.697+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:29:57.696+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:29:57.797+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:29:57.795+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:29:57.800+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:29:57.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.209 seconds
[2024-01-03T15:30:28.747+0000] {processor.py:157} INFO - Started process (PID=5006) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:30:28.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:30:28.754+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:30:28.750+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:30:28.798+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:30:28.796+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:30:28.799+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:30:28.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.084 seconds
[2024-01-03T15:30:59.340+0000] {processor.py:157} INFO - Started process (PID=5038) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:30:59.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:30:59.350+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:30:59.348+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:30:59.399+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:30:59.397+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:30:59.400+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:30:59.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.091 seconds
[2024-01-03T15:31:29.912+0000] {processor.py:157} INFO - Started process (PID=5070) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:31:29.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:31:29.916+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:31:29.915+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:31:29.947+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:31:29.945+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:31:29.947+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:31:30.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.556 seconds
[2024-01-03T15:32:01.062+0000] {processor.py:157} INFO - Started process (PID=5102) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:32:01.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:32:01.066+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:32:01.065+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:32:01.117+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:32:01.115+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:32:01.117+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:32:01.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.088 seconds
[2024-01-03T15:32:31.683+0000] {processor.py:157} INFO - Started process (PID=5134) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:32:31.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:32:31.687+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:32:31.687+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:32:31.717+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:32:31.716+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:32:31.718+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:32:31.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.077 seconds
[2024-01-03T15:32:59.615+0000] {processor.py:157} INFO - Started process (PID=5166) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:32:59.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:32:59.620+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:32:59.619+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:32:59.669+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:32:59.668+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 76, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T15:32:59.670+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:32:59.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.110 seconds
[2024-01-03T15:33:30.728+0000] {processor.py:157} INFO - Started process (PID=5198) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:33:30.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:33:30.731+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:33:30.730+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:33:30.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:33:31.386+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:33:31.386+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:33:31.404+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:33:31.404+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:33:31.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.701 seconds
[2024-01-03T15:34:01.534+0000] {processor.py:157} INFO - Started process (PID=5230) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:01.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:34:01.538+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:01.537+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:01.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:02.799+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:02.798+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:34:02.830+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:02.830+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:34:02.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 1.317 seconds
[2024-01-03T15:34:13.173+0000] {processor.py:157} INFO - Started process (PID=5245) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:13.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:34:13.178+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:13.177+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:13.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:13.610+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:13.610+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:34:13.627+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:13.626+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:34:13.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.480 seconds
[2024-01-03T15:34:33.701+0000] {processor.py:157} INFO - Started process (PID=5267) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:33.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:34:33.707+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:33.706+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:34.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:34.105+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:34.104+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:34:34.132+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:34.132+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:34:34.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.467 seconds
[2024-01-03T15:34:59.129+0000] {processor.py:157} INFO - Started process (PID=5299) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:59.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:34:59.135+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:59.134+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:59.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:34:59.343+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:59.342+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:34:59.390+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:34:59.390+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:35:00.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 1.290 seconds
[2024-01-03T15:35:02.290+0000] {processor.py:157} INFO - Started process (PID=5304) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:35:02.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:35:02.294+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:35:02.294+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:35:02.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:35:02.396+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:35:02.395+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:35:02.433+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:35:02.433+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:35:02.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.557 seconds
[2024-01-03T15:35:33.625+0000] {processor.py:157} INFO - Started process (PID=5336) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:35:33.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:35:33.629+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:35:33.628+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:35:33.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:35:33.723+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:35:33.723+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:35:34.178+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:35:34.177+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:35:34.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.582 seconds
[2024-01-03T15:36:05.345+0000] {processor.py:157} INFO - Started process (PID=5371) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:36:05.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:36:05.351+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:36:05.350+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:36:05.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:36:05.467+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:36:05.467+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:36:05.933+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:36:05.933+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:36:05.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.609 seconds
[2024-01-03T15:36:36.917+0000] {processor.py:157} INFO - Started process (PID=5403) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:36:36.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:36:36.922+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:36:36.921+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:36:36.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:36:37.321+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:36:37.321+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:36:37.339+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:36:37.339+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:36:37.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.450 seconds
[2024-01-03T15:37:08.375+0000] {processor.py:157} INFO - Started process (PID=5435) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:37:08.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:37:08.380+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:37:08.379+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:37:08.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:37:08.857+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:37:08.857+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:37:08.872+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:37:08.871+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:37:08.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.527 seconds
[2024-01-03T15:37:39.724+0000] {processor.py:157} INFO - Started process (PID=5467) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:37:39.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:37:39.729+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:37:39.728+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:37:39.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:37:39.819+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:37:39.819+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:37:39.863+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:37:39.862+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:37:39.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.172 seconds
[2024-01-03T15:38:10.528+0000] {processor.py:157} INFO - Started process (PID=5500) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:38:10.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:38:10.534+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:38:10.533+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:38:10.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:38:10.642+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:38:10.642+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:38:11.019+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:38:11.018+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:38:11.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.516 seconds
[2024-01-03T15:38:41.776+0000] {processor.py:157} INFO - Started process (PID=5532) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:38:41.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:38:41.785+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:38:41.784+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:38:41.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:38:41.920+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:38:41.920+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:38:42.586+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:38:42.586+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:38:42.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.910 seconds
[2024-01-03T15:39:13.524+0000] {processor.py:157} INFO - Started process (PID=5574) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:39:13.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:39:13.527+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:39:13.527+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:39:13.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:39:13.912+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:39:13.911+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:39:13.930+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:39:13.929+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:39:13.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.425 seconds
[2024-01-03T15:39:44.174+0000] {processor.py:157} INFO - Started process (PID=5606) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:39:44.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:39:44.178+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:39:44.177+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:39:44.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:39:44.541+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:39:44.541+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:39:44.558+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:39:44.558+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:39:44.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.400 seconds
[2024-01-03T15:40:15.050+0000] {processor.py:157} INFO - Started process (PID=5638) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:40:15.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:40:15.067+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:40:15.064+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:40:15.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:40:15.315+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:40:15.315+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:40:15.384+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:40:15.384+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:40:15.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.375 seconds
[2024-01-03T15:40:46.132+0000] {processor.py:157} INFO - Started process (PID=5670) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:40:46.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:40:46.136+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:40:46.136+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:40:46.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:40:46.192+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:40:46.192+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:40:46.235+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:40:46.235+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:40:46.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.490 seconds
[2024-01-03T15:41:17.460+0000] {processor.py:157} INFO - Started process (PID=5702) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:41:17.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:41:17.463+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:41:17.462+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:41:17.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:41:17.534+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:41:17.534+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:41:17.888+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:41:17.888+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:41:17.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.447 seconds
[2024-01-03T15:41:48.047+0000] {processor.py:157} INFO - Started process (PID=5734) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:41:48.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:41:48.053+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:41:48.051+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:41:48.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:41:48.150+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:41:48.150+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:41:48.576+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:41:48.576+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:41:48.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.574 seconds
[2024-01-03T15:42:18.778+0000] {processor.py:157} INFO - Started process (PID=5766) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:42:18.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:42:18.781+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:42:18.780+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:42:18.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:42:19.156+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:42:19.156+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:42:19.177+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:42:19.177+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:42:19.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.420 seconds
[2024-01-03T15:42:49.377+0000] {processor.py:157} INFO - Started process (PID=5798) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:42:49.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:42:49.380+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:42:49.380+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:42:49.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:42:49.871+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:42:49.871+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:42:49.891+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:42:49.891+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:42:49.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.535 seconds
[2024-01-03T15:43:20.653+0000] {processor.py:157} INFO - Started process (PID=5830) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:43:20.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:43:20.657+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:43:20.656+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:43:20.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:43:20.790+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:43:20.790+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:43:20.831+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:43:20.831+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:43:21.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.879 seconds
[2024-01-03T15:43:51.559+0000] {processor.py:157} INFO - Started process (PID=5862) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:43:51.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:43:51.561+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:43:51.560+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:43:51.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:43:51.613+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:43:51.612+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:43:52.017+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:43:52.017+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:43:52.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.481 seconds
[2024-01-03T15:44:22.836+0000] {processor.py:157} INFO - Started process (PID=5894) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:44:22.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:44:22.840+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:44:22.839+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:44:22.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:44:22.897+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:44:22.897+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:44:23.236+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:44:23.235+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:44:23.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.419 seconds
[2024-01-03T15:44:53.531+0000] {processor.py:157} INFO - Started process (PID=5925) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:44:53.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:44:53.535+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:44:53.534+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:44:53.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:44:53.926+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:44:53.925+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:44:53.948+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:44:53.948+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:44:53.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.435 seconds
[2024-01-03T15:45:24.726+0000] {processor.py:157} INFO - Started process (PID=5957) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:45:24.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:45:24.731+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:45:24.730+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:45:25.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:45:25.110+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:45:25.109+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:45:25.126+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:45:25.126+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:45:25.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.439 seconds
[2024-01-03T15:45:55.775+0000] {processor.py:157} INFO - Started process (PID=5989) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:45:55.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:45:55.779+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:45:55.778+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:45:56.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:45:56.296+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:45:56.296+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:45:56.313+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:45:56.313+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:45:56.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.562 seconds
[2024-01-03T15:46:27.091+0000] {processor.py:157} INFO - Started process (PID=6028) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:46:27.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:46:27.095+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:46:27.094+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:46:27.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:46:27.191+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:46:27.190+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:46:27.215+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:46:27.215+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:46:27.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.150 seconds
[2024-01-03T15:46:57.722+0000] {processor.py:157} INFO - Started process (PID=6060) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:46:57.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:46:57.727+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:46:57.726+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:46:57.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:46:57.812+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:46:57.811+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:46:57.832+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:46:57.832+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:46:57.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.132 seconds
[2024-01-03T15:47:28.382+0000] {processor.py:157} INFO - Started process (PID=6092) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:47:28.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:47:28.387+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:47:28.386+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:47:28.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:47:28.472+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:47:28.472+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:47:28.492+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:47:28.492+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:47:28.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.132 seconds
[2024-01-03T15:47:59.089+0000] {processor.py:157} INFO - Started process (PID=6124) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:47:59.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:47:59.094+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:47:59.092+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:47:59.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:47:59.179+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:47:59.178+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:47:59.200+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:47:59.200+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:47:59.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.136 seconds
[2024-01-03T15:48:29.880+0000] {processor.py:157} INFO - Started process (PID=6156) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:48:29.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:48:29.885+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:48:29.885+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:48:29.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:48:29.963+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:48:29.963+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:48:29.984+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:48:29.984+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:48:29.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.129 seconds
[2024-01-03T15:49:00.723+0000] {processor.py:157} INFO - Started process (PID=6189) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:49:00.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:49:00.727+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:49:00.727+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:49:00.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:49:00.808+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:49:00.808+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:49:00.831+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:49:00.830+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:49:00.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.138 seconds
[2024-01-03T15:49:31.501+0000] {processor.py:157} INFO - Started process (PID=6221) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:49:31.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:49:31.505+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:49:31.504+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:49:31.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:49:31.589+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:49:31.588+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:49:31.611+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:49:31.611+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:49:31.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.134 seconds
[2024-01-03T15:50:02.198+0000] {processor.py:157} INFO - Started process (PID=6253) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:50:02.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:50:02.206+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:50:02.204+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:50:02.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:50:02.278+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:50:02.278+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:50:02.301+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:50:02.300+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:50:02.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.142 seconds
[2024-01-03T15:50:32.495+0000] {processor.py:157} INFO - Started process (PID=6286) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:50:32.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:50:32.504+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:50:32.503+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:50:32.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:50:32.647+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:50:32.646+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:50:32.677+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:50:32.677+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:50:32.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.224 seconds
[2024-01-03T15:51:02.966+0000] {processor.py:157} INFO - Started process (PID=6321) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:51:02.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:51:02.973+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:51:02.972+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:51:03.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:51:03.166+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:51:03.166+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:51:03.211+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:51:03.211+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:51:03.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.284 seconds
[2024-01-03T15:51:34.126+0000] {processor.py:157} INFO - Started process (PID=6353) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:51:34.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:51:34.129+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:51:34.129+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:51:34.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:51:34.219+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:51:34.219+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:51:34.240+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:51:34.240+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:51:34.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.145 seconds
[2024-01-03T15:52:04.333+0000] {processor.py:157} INFO - Started process (PID=6388) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:52:04.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:52:04.336+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:52:04.335+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:52:04.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:52:04.408+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:52:04.407+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:52:04.443+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:52:04.443+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:52:04.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.132 seconds
[2024-01-03T15:52:35.138+0000] {processor.py:157} INFO - Started process (PID=6417) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:52:35.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:52:35.142+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:52:35.141+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:52:35.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:52:35.237+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:52:35.237+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:52:35.262+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:52:35.262+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:52:35.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.152 seconds
[2024-01-03T15:53:05.822+0000] {processor.py:157} INFO - Started process (PID=6449) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:53:05.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:53:05.826+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:53:05.826+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:53:05.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:53:05.901+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:53:05.901+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:53:05.921+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:53:05.921+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:53:05.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.136 seconds
[2024-01-03T15:53:36.601+0000] {processor.py:157} INFO - Started process (PID=6481) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:53:36.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:53:36.604+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:53:36.604+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:53:36.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:53:36.668+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:53:36.668+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:53:36.689+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:53:36.689+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:53:36.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.108 seconds
[2024-01-03T15:54:07.218+0000] {processor.py:157} INFO - Started process (PID=6513) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:54:07.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:54:07.223+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:54:07.222+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:54:07.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:54:07.305+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:54:07.305+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:54:07.325+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:54:07.325+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:54:07.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.130 seconds
[2024-01-03T15:54:37.658+0000] {processor.py:157} INFO - Started process (PID=6545) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:54:37.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:54:37.663+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:54:37.662+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:54:37.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:54:37.780+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:54:37.780+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:54:37.809+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:54:37.808+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:54:37.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.177 seconds
[2024-01-03T15:55:07.879+0000] {processor.py:157} INFO - Started process (PID=6580) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:55:07.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:55:07.883+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:55:07.883+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:55:07.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:55:07.986+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:55:07.985+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:55:08.010+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:55:08.010+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:55:08.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.156 seconds
[2024-01-03T15:55:38.628+0000] {processor.py:157} INFO - Started process (PID=6614) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:55:38.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:55:38.632+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:55:38.631+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:55:38.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:55:38.845+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:55:38.845+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:55:38.926+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:55:38.926+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:55:38.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.352 seconds
[2024-01-03T15:56:09.820+0000] {processor.py:157} INFO - Started process (PID=6646) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:56:09.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:56:09.823+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:56:09.822+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:56:09.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:56:09.918+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:56:09.917+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:56:09.943+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:56:09.943+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:56:09.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.144 seconds
[2024-01-03T15:56:40.782+0000] {processor.py:157} INFO - Started process (PID=6678) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:56:40.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:56:40.838+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:56:40.789+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:56:40.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:56:41.221+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:56:41.220+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:56:41.326+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:56:41.326+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:56:41.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.649 seconds
[2024-01-03T15:57:11.688+0000] {processor.py:157} INFO - Started process (PID=6710) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:57:11.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:57:11.691+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:57:11.691+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:57:11.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:57:11.757+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:57:11.757+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:57:11.793+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:57:11.793+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:57:11.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.126 seconds
[2024-01-03T15:57:41.882+0000] {processor.py:157} INFO - Started process (PID=6742) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:57:41.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:57:41.885+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:57:41.884+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:57:41.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:57:41.980+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:57:41.980+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:57:42.006+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:57:42.006+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:57:42.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.147 seconds
[2024-01-03T15:58:12.680+0000] {processor.py:157} INFO - Started process (PID=6774) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:58:12.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:58:12.710+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:58:12.708+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:58:12.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:58:12.814+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:58:12.814+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:58:12.859+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:58:12.858+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:58:12.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.220 seconds
[2024-01-03T15:58:43.554+0000] {processor.py:157} INFO - Started process (PID=6806) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:58:43.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:58:43.560+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:58:43.559+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:58:43.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:58:43.664+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:58:43.663+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:58:43.715+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:58:43.715+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:58:43.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.198 seconds
[2024-01-03T15:59:14.573+0000] {processor.py:157} INFO - Started process (PID=6838) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:59:14.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:59:14.576+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:59:14.575+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:59:14.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:59:14.684+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:59:14.683+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:59:14.709+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:59:14.709+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:59:14.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.163 seconds
[2024-01-03T15:59:45.229+0000] {processor.py:157} INFO - Started process (PID=6870) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:59:45.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T15:59:45.232+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:59:45.231+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:59:45.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T15:59:45.337+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:59:45.336+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T15:59:45.371+0000] {logging_mixin.py:154} INFO - [2024-01-03T15:59:45.371+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T15:59:45.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.167 seconds
[2024-01-03T16:00:15.885+0000] {processor.py:157} INFO - Started process (PID=6902) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:00:15.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:00:15.888+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:00:15.888+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:00:15.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:00:15.989+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:00:15.989+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:00:16.013+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:00:16.012+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:00:16.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.149 seconds
[2024-01-03T16:00:46.993+0000] {processor.py:157} INFO - Started process (PID=6934) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:00:46.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:00:46.996+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:00:46.995+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:00:47.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:00:47.071+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:00:47.071+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:00:47.224+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:00:47.224+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:00:47.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.315 seconds
[2024-01-03T16:01:18.002+0000] {processor.py:157} INFO - Started process (PID=6966) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:01:18.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:01:18.010+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:01:18.009+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:01:18.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:01:18.134+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:01:18.134+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:01:18.162+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:01:18.162+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:01:18.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.188 seconds
[2024-01-03T16:01:48.768+0000] {processor.py:157} INFO - Started process (PID=6998) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:01:48.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:01:48.771+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:01:48.771+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:01:48.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:01:48.836+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:01:48.836+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:01:48.859+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:01:48.859+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:01:48.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.113 seconds
[2024-01-03T16:02:19.515+0000] {processor.py:157} INFO - Started process (PID=7030) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:02:19.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:02:19.518+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:02:19.518+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:02:19.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:02:19.618+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:02:19.618+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:02:19.641+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:02:19.641+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:02:19.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.154 seconds
[2024-01-03T16:02:49.845+0000] {processor.py:157} INFO - Started process (PID=7062) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:02:49.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:02:49.848+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:02:49.848+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:02:49.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:02:50.019+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:02:50.019+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:02:50.054+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:02:50.054+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:02:50.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.233 seconds
[2024-01-03T16:03:20.365+0000] {processor.py:157} INFO - Started process (PID=7094) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:03:20.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:03:20.368+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:03:20.368+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:03:20.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:03:20.438+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:03:20.438+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:03:20.463+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:03:20.463+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:03:20.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.120 seconds
[2024-01-03T16:03:50.948+0000] {processor.py:157} INFO - Started process (PID=7125) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:03:50.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:03:50.951+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:03:50.951+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:03:50.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:03:51.018+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:03:51.018+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:03:51.047+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:03:51.047+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:03:51.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.118 seconds
[2024-01-03T16:04:21.544+0000] {processor.py:157} INFO - Started process (PID=7157) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:04:21.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:04:21.547+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:04:21.547+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:04:21.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:04:21.606+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:04:21.606+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:04:21.627+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:04:21.627+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:04:21.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.102 seconds
[2024-01-03T16:04:52.288+0000] {processor.py:157} INFO - Started process (PID=7189) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:04:52.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:04:52.291+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:04:52.291+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:04:52.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:04:52.355+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:04:52.355+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:04:52.378+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:04:52.378+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:04:52.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.116 seconds
[2024-01-03T16:05:22.781+0000] {processor.py:157} INFO - Started process (PID=7221) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:05:22.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:05:22.784+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:05:22.784+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:05:22.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:05:22.856+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:05:22.856+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:05:22.878+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:05:22.878+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:05:22.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.118 seconds
[2024-01-03T16:05:53.663+0000] {processor.py:157} INFO - Started process (PID=7253) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:05:53.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:05:53.666+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:05:53.666+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:05:53.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:05:53.754+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:05:53.754+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:05:53.776+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:05:53.776+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:05:53.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.131 seconds
[2024-01-03T16:06:24.303+0000] {processor.py:157} INFO - Started process (PID=7285) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:06:24.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:06:24.307+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:06:24.306+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:06:24.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:06:24.383+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:06:24.383+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:06:24.410+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:06:24.410+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:06:24.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.130 seconds
[2024-01-03T16:06:54.987+0000] {processor.py:157} INFO - Started process (PID=7318) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:06:54.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:06:54.989+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:06:54.989+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:06:55.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:06:55.045+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:06:55.044+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:06:55.065+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:06:55.065+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:06:55.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.097 seconds
[2024-01-03T16:07:25.642+0000] {processor.py:157} INFO - Started process (PID=7350) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:07:25.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:07:25.645+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:07:25.644+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:07:25.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:07:25.714+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:07:25.713+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:07:25.738+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:07:25.738+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:07:25.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.140 seconds
[2024-01-03T16:07:56.139+0000] {processor.py:157} INFO - Started process (PID=7382) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:07:56.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:07:56.143+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:07:56.143+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:07:56.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:07:56.205+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:07:56.205+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:07:56.229+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:07:56.228+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:07:56.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.110 seconds
[2024-01-03T16:08:27.087+0000] {processor.py:157} INFO - Started process (PID=7414) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:08:27.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:08:27.091+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:08:27.090+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:08:27.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:08:27.238+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:08:27.238+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:08:27.267+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:08:27.267+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:08:27.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.208 seconds
[2024-01-03T16:08:57.889+0000] {processor.py:157} INFO - Started process (PID=7446) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:08:57.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:08:57.892+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:08:57.891+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:08:57.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:08:57.981+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:08:57.981+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:08:58.024+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:08:58.024+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:08:58.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.159 seconds
[2024-01-03T16:09:28.625+0000] {processor.py:157} INFO - Started process (PID=7478) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:09:28.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:09:28.630+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:09:28.629+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:09:28.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:09:28.809+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:09:28.808+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:09:28.839+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:09:28.839+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:09:28.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.244 seconds
[2024-01-03T16:09:59.450+0000] {processor.py:157} INFO - Started process (PID=7510) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:09:59.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:09:59.457+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:09:59.456+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:09:59.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:09:59.609+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:09:59.608+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:09:59.640+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:09:59.640+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:09:59.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.216 seconds
[2024-01-03T16:10:30.013+0000] {processor.py:157} INFO - Started process (PID=7542) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:10:30.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:10:30.015+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:10:30.015+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:10:30.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:10:30.085+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:10:30.085+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:10:30.110+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:10:30.110+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:10:30.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.119 seconds
[2024-01-03T16:11:00.605+0000] {processor.py:157} INFO - Started process (PID=7574) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:11:00.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:11:00.608+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:11:00.608+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:11:00.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:11:00.667+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:11:00.667+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:11:00.688+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:11:00.687+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:11:00.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.104 seconds
[2024-01-03T16:11:31.311+0000] {processor.py:157} INFO - Started process (PID=7606) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:11:31.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:11:31.314+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:11:31.314+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:11:31.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:11:31.375+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:11:31.375+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:11:31.398+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:11:31.398+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:11:31.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.105 seconds
[2024-01-03T16:12:01.951+0000] {processor.py:157} INFO - Started process (PID=7639) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:12:01.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:12:01.954+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:12:01.954+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:12:01.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:12:02.013+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:12:02.013+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:12:02.037+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:12:02.036+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:12:02.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.114 seconds
[2024-01-03T16:12:32.826+0000] {processor.py:157} INFO - Started process (PID=7671) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:12:32.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:12:32.828+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:12:32.828+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:12:32.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:12:32.888+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:12:32.888+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:12:32.909+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:12:32.909+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:12:32.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.101 seconds
[2024-01-03T16:13:03.371+0000] {processor.py:157} INFO - Started process (PID=7703) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:13:03.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:13:03.375+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:13:03.374+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:13:03.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:13:03.436+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:13:03.435+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:13:03.457+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:13:03.456+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:13:03.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.106 seconds
[2024-01-03T16:13:33.878+0000] {processor.py:157} INFO - Started process (PID=7735) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:13:33.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:13:33.881+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:13:33.881+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:13:33.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:13:33.952+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:13:33.952+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:13:33.976+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:13:33.975+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:13:33.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.117 seconds
[2024-01-03T16:14:04.442+0000] {processor.py:157} INFO - Started process (PID=7767) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:14:04.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:14:04.445+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:14:04.444+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:14:04.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:14:04.503+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:14:04.503+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:14:04.526+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:14:04.526+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:14:04.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.103 seconds
[2024-01-03T16:14:35.088+0000] {processor.py:157} INFO - Started process (PID=7799) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:14:35.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:14:35.092+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:14:35.091+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:14:35.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:14:35.151+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:14:35.151+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:14:35.191+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:14:35.191+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:14:35.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.131 seconds
[2024-01-03T16:15:05.801+0000] {processor.py:157} INFO - Started process (PID=7831) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:15:05.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:15:05.805+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:15:05.804+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:15:05.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:15:05.911+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:15:05.910+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:15:05.950+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:15:05.950+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:15:05.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.177 seconds
[2024-01-03T16:15:36.471+0000] {processor.py:157} INFO - Started process (PID=7863) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:15:36.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:15:36.475+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:15:36.474+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:15:36.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:15:36.562+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:15:36.562+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:15:36.585+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:15:36.585+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:15:36.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.137 seconds
[2024-01-03T16:16:07.343+0000] {processor.py:157} INFO - Started process (PID=7895) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:16:07.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:16:07.347+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:16:07.346+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:16:07.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:16:07.422+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:16:07.422+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:16:07.453+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:16:07.453+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:16:07.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.136 seconds
[2024-01-03T16:16:37.869+0000] {processor.py:157} INFO - Started process (PID=7934) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:16:37.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:16:37.871+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:16:37.871+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:16:37.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:16:37.925+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:16:37.925+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:16:37.951+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:16:37.951+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:16:37.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.112 seconds
[2024-01-03T16:17:08.376+0000] {processor.py:157} INFO - Started process (PID=7966) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:17:08.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:17:08.378+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:17:08.378+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:17:08.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:17:08.463+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:17:08.463+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:17:08.487+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:17:08.487+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:17:08.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.128 seconds
[2024-01-03T16:17:38.889+0000] {processor.py:157} INFO - Started process (PID=7998) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:17:38.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:17:38.892+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:17:38.891+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:17:38.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:17:38.961+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:17:38.961+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:17:38.986+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:17:38.985+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:17:39.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.118 seconds
[2024-01-03T16:18:09.605+0000] {processor.py:157} INFO - Started process (PID=8030) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:18:09.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:18:09.608+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:18:09.608+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:18:09.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:18:09.672+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:18:09.672+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:18:09.695+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:18:09.695+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:18:09.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.115 seconds
[2024-01-03T16:18:40.214+0000] {processor.py:157} INFO - Started process (PID=8062) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:18:40.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:18:40.217+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:18:40.217+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:18:40.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:18:40.308+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:18:40.308+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:18:40.332+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:18:40.331+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:18:40.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.137 seconds
[2024-01-03T16:19:10.876+0000] {processor.py:157} INFO - Started process (PID=8094) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:19:10.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:19:10.880+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:19:10.879+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:19:10.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:19:10.951+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:19:10.951+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:19:10.976+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:19:10.975+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:19:10.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.123 seconds
[2024-01-03T16:19:41.391+0000] {processor.py:157} INFO - Started process (PID=8126) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:19:41.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:19:41.395+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:19:41.394+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:19:41.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:19:41.468+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:19:41.468+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:19:41.490+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:19:41.489+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:19:41.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.118 seconds
[2024-01-03T16:20:11.983+0000] {processor.py:157} INFO - Started process (PID=8158) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:20:11.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:20:11.987+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:20:11.986+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:20:12.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:20:12.078+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:20:12.077+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:20:12.109+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:20:12.109+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:20:12.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.147 seconds
[2024-01-03T16:20:42.720+0000] {processor.py:157} INFO - Started process (PID=8189) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:20:42.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:20:42.724+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:20:42.723+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:20:42.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:20:42.808+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:20:42.807+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:20:42.844+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:20:42.844+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:20:42.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.149 seconds
[2024-01-03T16:21:13.237+0000] {processor.py:157} INFO - Started process (PID=8221) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:21:13.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:21:13.240+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:21:13.240+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:21:13.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:21:13.301+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:21:13.301+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:21:13.321+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:21:13.321+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:21:13.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.105 seconds
[2024-01-03T16:21:43.862+0000] {processor.py:157} INFO - Started process (PID=8253) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:21:43.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:21:43.871+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:21:43.871+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:21:43.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:21:43.948+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:21:43.948+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:21:43.971+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:21:43.971+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:21:43.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.147 seconds
[2024-01-03T16:22:14.276+0000] {processor.py:157} INFO - Started process (PID=8285) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:22:14.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:22:14.278+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:22:14.277+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:22:14.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:22:14.334+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:22:14.334+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:22:14.366+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:22:14.366+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:22:14.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.111 seconds
[2024-01-03T16:22:44.974+0000] {processor.py:157} INFO - Started process (PID=8317) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:22:44.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:22:44.976+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:22:44.976+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:22:45.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:22:45.056+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:22:45.056+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:22:45.085+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:22:45.085+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:22:45.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.132 seconds
[2024-01-03T16:23:15.662+0000] {processor.py:157} INFO - Started process (PID=8349) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:23:15.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:23:15.666+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:23:15.665+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:23:15.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:23:15.738+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:23:15.737+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:23:15.764+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:23:15.764+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:23:15.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.127 seconds
[2024-01-03T16:23:46.175+0000] {processor.py:157} INFO - Started process (PID=8381) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:23:46.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:23:46.178+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:23:46.178+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:23:46.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:23:46.243+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:23:46.243+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:23:46.264+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:23:46.264+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:23:46.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.106 seconds
[2024-01-03T16:24:16.771+0000] {processor.py:157} INFO - Started process (PID=8413) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:24:16.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:24:16.775+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:24:16.775+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:24:16.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:24:16.834+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:24:16.833+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:24:16.856+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:24:16.855+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:24:16.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.105 seconds
[2024-01-03T16:24:47.380+0000] {processor.py:157} INFO - Started process (PID=8445) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:24:47.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:24:47.384+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:24:47.383+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:24:47.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:24:47.466+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:24:47.466+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:24:47.492+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:24:47.491+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:24:47.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.134 seconds
[2024-01-03T16:25:18.211+0000] {processor.py:157} INFO - Started process (PID=8477) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:25:18.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:25:18.216+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:25:18.215+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:25:18.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:25:18.361+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:25:18.361+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:25:18.396+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:25:18.396+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:25:18.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.234 seconds
[2024-01-03T16:25:48.966+0000] {processor.py:157} INFO - Started process (PID=8509) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:25:48.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:25:48.968+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:25:48.968+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:25:49.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:25:49.025+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:25:49.025+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:25:49.060+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:25:49.060+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:25:49.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.115 seconds
[2024-01-03T16:26:19.591+0000] {processor.py:157} INFO - Started process (PID=8541) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:26:19.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:26:19.595+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:26:19.594+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:26:19.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:26:19.716+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:26:19.716+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:26:19.759+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:26:19.759+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:26:19.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.197 seconds
[2024-01-03T16:26:50.316+0000] {processor.py:157} INFO - Started process (PID=8573) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:26:50.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:26:50.321+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:26:50.320+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:26:50.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:26:50.413+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:26:50.413+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:26:50.436+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:26:50.436+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:26:50.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.142 seconds
[2024-01-03T16:27:20.954+0000] {processor.py:157} INFO - Started process (PID=8605) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:27:20.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:27:20.957+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:27:20.957+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:27:20.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:27:21.016+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:27:21.016+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:27:21.039+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:27:21.039+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:27:21.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.107 seconds
[2024-01-03T16:27:51.534+0000] {processor.py:157} INFO - Started process (PID=8637) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:27:51.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:27:51.538+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:27:51.537+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:27:51.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:27:51.603+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:27:51.603+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:27:51.624+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:27:51.623+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:27:51.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.109 seconds
[2024-01-03T16:28:22.100+0000] {processor.py:157} INFO - Started process (PID=8669) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:28:22.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:28:22.104+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:28:22.103+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:28:22.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:28:22.206+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:28:22.206+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:28:22.231+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:28:22.231+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:28:22.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.152 seconds
[2024-01-03T16:28:52.636+0000] {processor.py:157} INFO - Started process (PID=8701) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:28:52.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:28:52.640+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:28:52.640+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:28:52.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:28:52.720+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:28:52.720+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:28:52.744+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:28:52.744+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:28:52.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.127 seconds
[2024-01-03T16:29:23.113+0000] {processor.py:157} INFO - Started process (PID=8733) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:29:23.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:29:23.117+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:29:23.116+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:29:23.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:29:23.173+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:29:23.173+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:29:23.193+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:29:23.193+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:29:23.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.098 seconds
[2024-01-03T16:29:53.573+0000] {processor.py:157} INFO - Started process (PID=8765) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:29:53.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:29:53.575+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:29:53.575+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:29:53.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:29:53.638+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:29:53.638+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:29:53.672+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:29:53.672+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:29:53.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.117 seconds
[2024-01-03T16:30:24.044+0000] {processor.py:157} INFO - Started process (PID=8797) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:30:24.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:30:24.047+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:30:24.046+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:30:24.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:30:24.126+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:30:24.125+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:30:24.149+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:30:24.149+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:30:24.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.129 seconds
[2024-01-03T16:30:54.499+0000] {processor.py:157} INFO - Started process (PID=8829) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:30:54.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:30:54.501+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:30:54.501+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:30:54.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:30:54.582+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:30:54.581+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:30:54.605+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:30:54.605+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:30:54.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.127 seconds
[2024-01-03T16:31:25.314+0000] {processor.py:157} INFO - Started process (PID=8861) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:31:25.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:31:25.321+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:31:25.320+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:31:25.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:31:25.455+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:31:25.455+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:31:25.491+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:31:25.491+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:31:25.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.208 seconds
[2024-01-03T16:31:55.946+0000] {processor.py:157} INFO - Started process (PID=8893) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:31:55.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:31:55.949+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:31:55.949+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:31:55.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:31:56.009+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:31:56.008+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:31:56.028+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:31:56.028+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:31:56.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.101 seconds
[2024-01-03T16:32:26.544+0000] {processor.py:157} INFO - Started process (PID=8925) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:32:26.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:32:26.548+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:32:26.547+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:32:26.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:32:26.640+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:32:26.640+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:32:26.665+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:32:26.665+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:32:26.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.172 seconds
[2024-01-03T16:32:57.131+0000] {processor.py:157} INFO - Started process (PID=8957) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:32:57.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:32:57.134+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:32:57.134+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:32:57.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:32:57.195+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:32:57.195+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:32:57.228+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:32:57.228+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:32:57.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.119 seconds
[2024-01-03T16:33:27.927+0000] {processor.py:157} INFO - Started process (PID=8989) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:33:27.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:33:27.932+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:33:27.932+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:33:27.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:33:28.050+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:33:28.050+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:33:28.078+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:33:28.077+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:33:28.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.175 seconds
[2024-01-03T16:33:58.490+0000] {processor.py:157} INFO - Started process (PID=9021) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:33:58.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:33:58.493+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:33:58.493+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:33:58.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:33:58.554+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:33:58.553+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:33:58.576+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:33:58.576+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:33:58.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.104 seconds
[2024-01-03T16:34:29.072+0000] {processor.py:157} INFO - Started process (PID=9053) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:34:29.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:34:29.077+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:34:29.076+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:34:29.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:34:29.488+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:34:29.487+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:34:29.545+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:34:29.545+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:34:29.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.541 seconds
[2024-01-03T16:34:59.768+0000] {processor.py:157} INFO - Started process (PID=9085) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:34:59.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:34:59.771+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:34:59.771+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:34:59.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:34:59.836+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:34:59.836+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:34:59.858+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:34:59.858+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:34:59.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.110 seconds
[2024-01-03T16:35:30.583+0000] {processor.py:157} INFO - Started process (PID=9117) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:35:30.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:35:30.592+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:35:30.590+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:35:30.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:35:30.822+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:35:30.822+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:35:30.853+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:35:30.853+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:35:30.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.327 seconds
[2024-01-03T16:36:01.479+0000] {processor.py:157} INFO - Started process (PID=9149) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:36:01.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:36:01.482+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:36:01.482+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:36:01.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:36:01.549+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:36:01.549+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:36:01.574+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:36:01.574+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:36:01.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.114 seconds
[2024-01-03T16:36:32.327+0000] {processor.py:157} INFO - Started process (PID=9181) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:36:32.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:36:32.331+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:36:32.331+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:36:32.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:36:32.389+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:36:32.389+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:36:32.410+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:36:32.410+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:36:32.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.104 seconds
[2024-01-03T16:37:03.000+0000] {processor.py:157} INFO - Started process (PID=9213) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:37:03.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:37:03.004+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:37:03.003+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:37:03.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:37:03.106+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:37:03.105+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:37:03.132+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:37:03.132+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:37:03.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.164 seconds
[2024-01-03T16:37:33.649+0000] {processor.py:157} INFO - Started process (PID=9245) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:37:33.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:37:33.652+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:37:33.652+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:37:33.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:37:33.744+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:37:33.744+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:37:33.767+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:37:33.767+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:37:33.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.139 seconds
[2024-01-03T16:38:04.252+0000] {processor.py:157} INFO - Started process (PID=9277) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:38:04.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:38:04.255+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:38:04.255+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:38:04.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:38:04.324+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:38:04.324+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:38:04.347+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:38:04.347+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:38:04.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.118 seconds
[2024-01-03T16:38:34.889+0000] {processor.py:157} INFO - Started process (PID=9309) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:38:34.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:38:34.892+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:38:34.892+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:38:34.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:38:34.959+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:38:34.959+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:38:34.982+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:38:34.982+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:38:34.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.115 seconds
[2024-01-03T16:39:05.480+0000] {processor.py:157} INFO - Started process (PID=9341) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:39:05.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:39:05.484+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:39:05.483+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:39:05.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:39:05.574+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:39:05.574+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:39:05.598+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:39:05.598+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:39:05.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.140 seconds
[2024-01-03T16:39:36.189+0000] {processor.py:157} INFO - Started process (PID=9373) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:39:36.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:39:36.192+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:39:36.192+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:39:36.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:39:36.260+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:39:36.260+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:39:36.283+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:39:36.283+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:39:36.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.115 seconds
[2024-01-03T16:40:02.721+0000] {processor.py:157} INFO - Started process (PID=9390) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:02.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:40:02.724+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:02.723+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:02.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:02.896+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:02.896+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:40:02.953+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:02.952+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:40:02.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.270 seconds
[2024-01-03T16:40:04.030+0000] {processor.py:157} INFO - Started process (PID=9405) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:04.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:40:04.036+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:04.035+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:04.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:04.129+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:04.128+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T16:40:04.212+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:04.208+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T16:40:04.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.320 seconds
[2024-01-03T16:40:11.673+0000] {processor.py:157} INFO - Started process (PID=9420) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:11.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:40:11.677+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:11.676+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:11.739+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:11.728+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 53, in <module>
    create_update_dim_product = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:40:11.739+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:11.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.159 seconds
[2024-01-03T16:40:16.873+0000] {processor.py:157} INFO - Started process (PID=9432) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:16.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:40:16.876+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:16.876+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:16.945+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:16.940+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 53, in <module>
    create_update_dim_customer = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:40:16.945+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:16.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.112 seconds
[2024-01-03T16:40:22.073+0000] {processor.py:157} INFO - Started process (PID=9437) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:22.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:40:22.076+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:22.075+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:22.131+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:22.128+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 54, in <module>
    create_update_dim_customer = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:40:22.132+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:22.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.092 seconds
[2024-01-03T16:40:29.344+0000] {processor.py:157} INFO - Started process (PID=9442) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:29.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:40:29.346+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:29.346+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:29.386+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:29.383+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 54, in <module>
    create_update_dim_customer = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:40:29.386+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:29.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.084 seconds
[2024-01-03T16:40:35.651+0000] {processor.py:157} INFO - Started process (PID=9462) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:35.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:40:35.654+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:35.653+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:35.695+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:35.692+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 54, in <module>
    create_update_dim_customer = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:40:35.696+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:35.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.095 seconds
[2024-01-03T16:40:39.973+0000] {processor.py:157} INFO - Started process (PID=9472) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:39.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:40:39.978+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:39.977+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:40.044+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:40.041+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 54, in <module>
    create_update_dim_customer = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:40:40.044+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:40.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.104 seconds
[2024-01-03T16:40:46.177+0000] {processor.py:157} INFO - Started process (PID=9484) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:46.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:40:46.181+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:46.180+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:46.250+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:40:46.247+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 54, in <module>
    create_update_dim_customer = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:40:46.251+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:40:46.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.106 seconds
[2024-01-03T16:41:03.443+0000] {processor.py:157} INFO - Started process (PID=9489) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:03.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:41:03.448+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:03.447+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:03.512+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:03.508+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 54, in <module>
    create_update_dim_product = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:41:03.513+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:03.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.118 seconds
[2024-01-03T16:41:05.556+0000] {processor.py:157} INFO - Started process (PID=9504) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:05.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:41:05.558+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:05.558+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:05.584+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:05.581+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 55, in <module>
    create_update_dim_product = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:41:05.585+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:05.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.048 seconds
[2024-01-03T16:41:23.094+0000] {processor.py:157} INFO - Started process (PID=9526) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:23.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:41:23.097+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:23.096+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:23.142+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:23.136+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 54, in <module>
    create_update_dim_customer = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:41:23.144+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:23.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.095 seconds
[2024-01-03T16:41:24.132+0000] {processor.py:157} INFO - Started process (PID=9531) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:24.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:41:24.135+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:24.134+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:24.162+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:24.159+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 55, in <module>
    create_update_dim_customer = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:41:24.163+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:24.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.074 seconds
[2024-01-03T16:41:30.411+0000] {processor.py:157} INFO - Started process (PID=9536) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:30.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:41:30.414+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:30.414+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:30.491+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:30.487+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 55, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:41:30.492+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:30.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.131 seconds
[2024-01-03T16:41:34.549+0000] {processor.py:157} INFO - Started process (PID=9541) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:34.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:41:34.553+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:34.553+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:34.597+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:34.594+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 56, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:41:34.598+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:34.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.100 seconds
[2024-01-03T16:41:37.957+0000] {processor.py:157} INFO - Started process (PID=9561) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:37.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:41:37.961+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:37.960+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:38.026+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:38.022+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 56, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:41:38.026+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:38.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.108 seconds
[2024-01-03T16:41:42.078+0000] {processor.py:157} INFO - Started process (PID=9571) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:42.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:41:42.081+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:42.081+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:42.131+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:42.128+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:41:42.132+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:42.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.087 seconds
[2024-01-03T16:41:53.514+0000] {processor.py:157} INFO - Started process (PID=9583) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:53.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:41:53.517+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:53.517+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:53.565+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:41:53.563+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:41:53.565+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:41:53.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.087 seconds
[2024-01-03T16:42:09.146+0000] {processor.py:157} INFO - Started process (PID=9603) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:09.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:42:09.150+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:09.150+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:09.220+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:09.218+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:42:09.220+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:09.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.105 seconds
[2024-01-03T16:42:24.545+0000] {processor.py:157} INFO - Started process (PID=9620) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:24.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:42:24.550+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:24.549+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:24.601+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:24.586+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:42:24.602+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:24.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.104 seconds
[2024-01-03T16:42:30.715+0000] {processor.py:157} INFO - Started process (PID=9625) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:30.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:42:30.718+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:30.718+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:30.777+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:30.775+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:42:30.778+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:30.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.091 seconds
[2024-01-03T16:42:35.961+0000] {processor.py:157} INFO - Started process (PID=9630) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:35.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:42:35.999+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:35.998+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:36.079+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:36.076+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:42:36.080+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:36.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.185 seconds
[2024-01-03T16:42:38.305+0000] {processor.py:157} INFO - Started process (PID=9650) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:38.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:42:38.308+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:38.307+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:38.397+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:38.395+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:42:38.398+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:38.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.143 seconds
[2024-01-03T16:42:45.545+0000] {processor.py:157} INFO - Started process (PID=9667) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:45.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:42:45.548+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:45.547+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:45.630+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:45.628+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:42:45.631+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:45.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.234 seconds
[2024-01-03T16:42:54.789+0000] {processor.py:157} INFO - Started process (PID=9672) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:54.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:42:54.793+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:54.793+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:54.837+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:42:54.835+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:42:54.838+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:42:54.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.104 seconds
[2024-01-03T16:43:25.692+0000] {processor.py:157} INFO - Started process (PID=9704) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:25.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:43:25.695+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:25.695+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:25.731+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:25.728+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 40, in <module>
    DimProduct_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_product.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_product.sql'
[2024-01-03T16:43:25.731+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:25.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.086 seconds
[2024-01-03T16:43:30.836+0000] {processor.py:157} INFO - Started process (PID=9709) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:30.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:43:30.839+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:30.839+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:30.910+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:30.908+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 41, in <module>
    DimCustomer_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_customer.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_customer.sql'
[2024-01-03T16:43:30.911+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:30.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.112 seconds
[2024-01-03T16:43:32.974+0000] {processor.py:157} INFO - Started process (PID=9714) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:32.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:43:32.977+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:32.976+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:33.016+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:33.014+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/create_update_dim_date.sql'
[2024-01-03T16:43:33.017+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:33.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.073 seconds
[2024-01-03T16:43:35.083+0000] {processor.py:157} INFO - Started process (PID=9719) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:35.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:43:35.087+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:35.086+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:35.140+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:35.138+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_query/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_query/create_update_dim_date.sql'
[2024-01-03T16:43:35.141+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:35.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.096 seconds
[2024-01-03T16:43:37.142+0000] {processor.py:157} INFO - Started process (PID=9724) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:37.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:43:37.145+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:37.145+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:37.171+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:43:37.170+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 42, in <module>
    DimDate_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_query/create_update_dim_date.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_query/create_update_dim_date.sql'
[2024-01-03T16:43:37.172+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:43:37.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.054 seconds
[2024-01-03T16:44:08.237+0000] {processor.py:157} INFO - Started process (PID=9756) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:44:08.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:44:08.243+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:44:08.242+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:44:08.297+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:44:08.294+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_query/create_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_query/create_update_fact_order.sql'
[2024-01-03T16:44:08.298+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:44:08.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.113 seconds
[2024-01-03T16:44:39.331+0000] {processor.py:157} INFO - Started process (PID=9788) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:44:39.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:44:39.335+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:44:39.335+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:44:39.412+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:44:39.406+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:44:39.413+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:44:39.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.118 seconds
[2024-01-03T16:45:10.378+0000] {processor.py:157} INFO - Started process (PID=9820) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:45:10.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:45:10.382+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:45:10.381+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:45:10.443+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:45:10.440+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:45:10.444+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:45:10.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.097 seconds
[2024-01-03T16:45:41.379+0000] {processor.py:157} INFO - Started process (PID=9852) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:45:41.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:45:41.383+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:45:41.382+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:45:41.443+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:45:41.439+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:45:41.443+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:45:41.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.093 seconds
[2024-01-03T16:46:11.948+0000] {processor.py:157} INFO - Started process (PID=9885) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:46:11.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:46:11.952+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:46:11.951+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:46:12.056+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:46:12.051+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:46:12.056+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:46:12.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.143 seconds
[2024-01-03T16:46:42.806+0000] {processor.py:157} INFO - Started process (PID=9917) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:46:42.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:46:42.811+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:46:42.810+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:46:42.858+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:46:42.855+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:46:42.859+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:46:42.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.094 seconds
[2024-01-03T16:47:13.565+0000] {processor.py:157} INFO - Started process (PID=9949) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:47:13.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:47:13.570+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:47:13.569+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:47:13.607+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:47:13.604+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:47:13.608+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:47:13.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.079 seconds
[2024-01-03T16:47:44.288+0000] {processor.py:157} INFO - Started process (PID=9981) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:47:44.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:47:44.293+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:47:44.292+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:47:44.335+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:47:44.332+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:47:44.335+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:47:44.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.076 seconds
[2024-01-03T16:48:14.953+0000] {processor.py:157} INFO - Started process (PID=10013) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:48:14.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:48:14.956+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:48:14.955+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:48:14.994+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:48:14.991+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:48:14.995+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:48:15.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.067 seconds
[2024-01-03T16:48:45.778+0000] {processor.py:157} INFO - Started process (PID=10045) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:48:45.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:48:45.792+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:48:45.788+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:48:45.845+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:48:45.842+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:48:45.846+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:48:45.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.108 seconds
[2024-01-03T16:49:16.542+0000] {processor.py:157} INFO - Started process (PID=10077) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:49:16.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:49:16.548+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:49:16.547+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:49:16.613+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:49:16.606+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:49:16.614+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:49:16.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.121 seconds
[2024-01-03T16:49:47.415+0000] {processor.py:157} INFO - Started process (PID=10109) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:49:47.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:49:47.431+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:49:47.429+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:49:47.490+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:49:47.485+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:49:47.491+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:49:47.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.106 seconds
[2024-01-03T16:50:18.184+0000] {processor.py:157} INFO - Started process (PID=10141) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:50:18.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:50:18.188+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:50:18.188+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:50:18.254+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:50:18.251+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:50:18.255+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:50:18.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.095 seconds
[2024-01-03T16:50:48.978+0000] {processor.py:157} INFO - Started process (PID=10179) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:50:48.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:50:48.985+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:50:48.984+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:50:49.120+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:50:49.116+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:50:49.121+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:50:49.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.203 seconds
[2024-01-03T16:51:19.500+0000] {processor.py:157} INFO - Started process (PID=10212) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:51:19.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:51:19.505+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:51:19.504+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:51:19.566+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:51:19.563+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:51:19.567+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:51:19.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.099 seconds
[2024-01-03T16:51:50.342+0000] {processor.py:157} INFO - Started process (PID=10244) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:51:50.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:51:50.347+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:51:50.346+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:51:50.430+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:51:50.425+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:51:50.431+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:51:50.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.178 seconds
[2024-01-03T16:52:21.187+0000] {processor.py:157} INFO - Started process (PID=10276) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:52:21.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:52:21.199+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:52:21.196+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:52:21.249+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:52:21.246+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:52:21.250+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:52:21.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.096 seconds
[2024-01-03T16:52:51.942+0000] {processor.py:157} INFO - Started process (PID=10308) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:52:51.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:52:51.946+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:52:51.945+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:52:52.009+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:52:52.006+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:52:52.010+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:52:52.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.100 seconds
[2024-01-03T16:53:22.699+0000] {processor.py:157} INFO - Started process (PID=10340) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:53:22.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:53:22.703+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:53:22.702+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:53:22.746+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:53:22.743+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:53:22.747+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:53:22.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.079 seconds
[2024-01-03T16:53:53.448+0000] {processor.py:157} INFO - Started process (PID=10372) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:53:53.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:53:53.452+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:53:53.451+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:53:53.518+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:53:53.515+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:53:53.519+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:53:53.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.108 seconds
[2024-01-03T16:54:24.125+0000] {processor.py:157} INFO - Started process (PID=10404) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:54:24.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:54:24.140+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:54:24.139+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:54:24.192+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:54:24.189+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:54:24.192+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:54:24.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.106 seconds
[2024-01-03T16:54:54.886+0000] {processor.py:157} INFO - Started process (PID=10436) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:54:54.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:54:54.890+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:54:54.889+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:54:55.003+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:54:54.990+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:54:55.005+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:54:55.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.185 seconds
[2024-01-03T16:55:25.742+0000] {processor.py:157} INFO - Started process (PID=10468) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:55:25.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:55:25.746+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:55:25.745+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:55:25.789+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:55:25.786+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:55:25.789+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:55:25.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.082 seconds
[2024-01-03T16:55:56.370+0000] {processor.py:157} INFO - Started process (PID=10500) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:55:56.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:55:56.374+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:55:56.374+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:55:56.433+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:55:56.430+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:55:56.434+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:55:56.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.089 seconds
[2024-01-03T16:56:27.094+0000] {processor.py:157} INFO - Started process (PID=10532) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:56:27.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:56:27.098+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:56:27.098+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:56:27.139+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:56:27.136+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:56:27.140+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:56:27.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.081 seconds
[2024-01-03T16:56:57.791+0000] {processor.py:157} INFO - Started process (PID=10564) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:56:57.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:56:57.801+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:56:57.799+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:56:57.848+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:56:57.845+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:56:57.849+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:56:57.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.081 seconds
[2024-01-03T16:57:28.447+0000] {processor.py:157} INFO - Started process (PID=10596) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:57:28.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:57:28.452+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:57:28.451+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:57:28.491+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:57:28.488+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:57:28.492+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:57:28.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.073 seconds
[2024-01-03T16:57:59.204+0000] {processor.py:157} INFO - Started process (PID=10628) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:57:59.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:57:59.209+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:57:59.208+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:57:59.275+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:57:59.272+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:57:59.276+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:57:59.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.110 seconds
[2024-01-03T16:58:30.106+0000] {processor.py:157} INFO - Started process (PID=10660) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:58:30.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:58:30.111+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:58:30.110+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:58:30.187+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:58:30.184+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:58:30.188+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:58:30.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.117 seconds
[2024-01-03T16:59:00.859+0000] {processor.py:157} INFO - Started process (PID=10692) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:59:00.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:59:00.863+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:59:00.862+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:59:00.901+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:59:00.898+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:59:00.901+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:59:00.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.066 seconds
[2024-01-03T16:59:31.661+0000] {processor.py:157} INFO - Started process (PID=10725) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:59:31.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T16:59:31.664+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:59:31.664+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:59:31.703+0000] {logging_mixin.py:154} INFO - [2024-01-03T16:59:31.700+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T16:59:31.703+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T16:59:31.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.078 seconds
[2024-01-03T17:00:02.446+0000] {processor.py:157} INFO - Started process (PID=10757) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:00:02.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:00:02.456+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:00:02.454+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:00:02.519+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:00:02.516+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T17:00:02.520+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:00:02.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.111 seconds
[2024-01-03T17:00:33.363+0000] {processor.py:157} INFO - Started process (PID=10789) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:00:33.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:00:33.368+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:00:33.367+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:00:33.469+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:00:33.465+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T17:00:33.470+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:00:33.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.148 seconds
[2024-01-03T17:01:04.179+0000] {processor.py:157} INFO - Started process (PID=10821) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:01:04.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:01:04.194+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:01:04.189+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:01:04.246+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:01:04.243+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T17:01:04.247+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:01:04.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.092 seconds
[2024-01-03T17:01:34.812+0000] {processor.py:157} INFO - Started process (PID=10853) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:01:34.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:01:34.816+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:01:34.815+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:01:34.935+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:01:34.926+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T17:01:34.936+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:01:34.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.160 seconds
[2024-01-03T17:02:04.664+0000] {processor.py:157} INFO - Started process (PID=10885) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:04.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:02:04.670+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:02:04.669+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:04.765+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:02:04.761+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 44, in <module>
    find
NameError: name 'find' is not defined
[2024-01-03T17:02:04.765+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:04.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.161 seconds
[2024-01-03T17:02:06.973+0000] {processor.py:157} INFO - Started process (PID=10905) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:06.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:02:06.974+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:02:06.974+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:07.019+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:02:07.018+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 44, in <module>
    finddwdwd
NameError: name 'finddwdwd' is not defined
[2024-01-03T17:02:07.020+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:07.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.070 seconds
[2024-01-03T17:02:08.096+0000] {processor.py:157} INFO - Started process (PID=10910) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:08.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:02:08.130+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:02:08.114+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:08.247+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:02:08.242+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:02:08.248+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:08.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.192 seconds
[2024-01-03T17:02:39.130+0000] {processor.py:157} INFO - Started process (PID=10942) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:39.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:02:39.135+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:02:39.134+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:39.174+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:02:39.171+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:02:39.174+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:02:39.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.077 seconds
[2024-01-03T17:03:09.869+0000] {processor.py:157} INFO - Started process (PID=10974) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:03:09.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:03:09.872+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:03:09.872+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:03:09.901+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:03:09.899+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:03:09.901+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:03:09.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.052 seconds
[2024-01-03T17:03:40.525+0000] {processor.py:157} INFO - Started process (PID=11006) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:03:40.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:03:40.528+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:03:40.528+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:03:40.562+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:03:40.560+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:03:40.563+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:03:40.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.060 seconds
[2024-01-03T17:04:11.174+0000] {processor.py:157} INFO - Started process (PID=11038) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:04:11.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:04:11.177+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:04:11.176+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:04:11.228+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:04:11.227+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:04:11.229+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:04:11.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.078 seconds
[2024-01-03T17:04:41.934+0000] {processor.py:157} INFO - Started process (PID=11070) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:04:41.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:04:41.937+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:04:41.936+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:04:41.998+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:04:41.996+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:04:41.999+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:04:42.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.098 seconds
[2024-01-03T17:05:12.696+0000] {processor.py:157} INFO - Started process (PID=11102) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:05:12.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:05:12.699+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:05:12.698+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:05:12.728+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:05:12.727+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:05:12.729+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:05:12.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.060 seconds
[2024-01-03T17:05:43.318+0000] {processor.py:157} INFO - Started process (PID=11134) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:05:43.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:05:43.321+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:05:43.321+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:05:43.353+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:05:43.352+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:05:43.354+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:05:43.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.060 seconds
[2024-01-03T17:06:13.979+0000] {processor.py:157} INFO - Started process (PID=11166) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:06:13.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:06:13.982+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:06:13.981+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:06:14.010+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:06:14.009+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:06:14.011+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:06:14.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.065 seconds
[2024-01-03T17:06:44.726+0000] {processor.py:157} INFO - Started process (PID=11198) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:06:44.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:06:44.730+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:06:44.730+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:06:44.832+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:06:44.828+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:06:44.833+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:06:44.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.152 seconds
[2024-01-03T17:07:15.444+0000] {processor.py:157} INFO - Started process (PID=11230) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:07:15.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:07:15.447+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:07:15.447+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:07:15.478+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:07:15.477+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:07:15.479+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:07:15.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.056 seconds
[2024-01-03T17:07:46.155+0000] {processor.py:157} INFO - Started process (PID=11262) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:07:46.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:07:46.159+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:07:46.159+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:07:46.198+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:07:46.196+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:07:46.199+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:07:46.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.079 seconds
[2024-01-03T17:08:16.964+0000] {processor.py:157} INFO - Started process (PID=11294) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:08:16.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:08:16.967+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:08:16.966+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:08:17.004+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:08:17.003+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:08:17.005+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:08:17.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.074 seconds
[2024-01-03T17:08:47.558+0000] {processor.py:157} INFO - Started process (PID=11326) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:08:47.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:08:47.560+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:08:47.560+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:08:47.598+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:08:47.593+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:08:47.599+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:08:47.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.067 seconds
[2024-01-03T17:09:18.180+0000] {processor.py:157} INFO - Started process (PID=11358) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:09:18.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:09:18.183+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:09:18.183+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:09:18.216+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:09:18.215+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:09:18.217+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:09:18.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.079 seconds
[2024-01-03T17:09:48.855+0000] {processor.py:157} INFO - Started process (PID=11390) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:09:48.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:09:48.859+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:09:48.859+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:09:48.911+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:09:48.910+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:09:48.912+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:09:48.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.089 seconds
[2024-01-03T17:10:19.765+0000] {processor.py:157} INFO - Started process (PID=11422) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:10:19.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:10:19.771+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:10:19.770+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:10:19.889+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:10:19.881+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:10:19.890+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:10:19.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.245 seconds
[2024-01-03T17:10:50.481+0000] {processor.py:157} INFO - Started process (PID=11454) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:10:50.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:10:50.484+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:10:50.483+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:10:50.514+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:10:50.512+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:10:50.515+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:10:50.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.059 seconds
[2024-01-03T17:11:21.123+0000] {processor.py:157} INFO - Started process (PID=11486) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:11:21.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:11:21.125+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:11:21.125+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:11:21.165+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:11:21.158+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:11:21.166+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:11:21.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.066 seconds
[2024-01-03T17:11:29.369+0000] {processor.py:157} INFO - Started process (PID=11503) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:11:29.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:11:29.373+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:11:29.372+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:11:29.412+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:11:29.411+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:11:29.413+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:11:29.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.076 seconds
[2024-01-03T17:11:40.660+0000] {processor.py:157} INFO - Started process (PID=11508) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:11:40.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:11:40.670+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:11:40.668+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:11:40.713+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:11:40.711+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:11:40.714+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:11:40.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.097 seconds
[2024-01-03T17:12:11.440+0000] {processor.py:157} INFO - Started process (PID=11540) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:11.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:12:11.444+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:11.443+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:11.503+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:11.501+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 43, in <module>
    FactOrder_sql_query = read_sql_file('/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql')
  File "/opt/airflow/dags/data_transform_BQ.py", line 37, in read_sql_file
    with open(file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/demo1/dags/SQL_querycreate_update_fact_order.sql'
[2024-01-03T17:12:11.504+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:11.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.099 seconds
[2024-01-03T17:12:18.602+0000] {processor.py:157} INFO - Started process (PID=11545) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:18.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:12:18.605+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:18.604+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:18.670+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:18.663+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T17:12:18.671+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:18.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.111 seconds
[2024-01-03T17:12:19.726+0000] {processor.py:157} INFO - Started process (PID=11550) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:19.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:12:19.730+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:19.729+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:19.760+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:19.758+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 57, in <module>
    create_update_dim_date = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T17:12:19.760+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:19.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.063 seconds
[2024-01-03T17:12:41.547+0000] {processor.py:157} INFO - Started process (PID=11582) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:41.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:12:41.554+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:41.554+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:41.608+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:41.605+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 68, in <module>
    create_update_dim_product = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T17:12:41.608+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:41.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.094 seconds
[2024-01-03T17:12:45.828+0000] {processor.py:157} INFO - Started process (PID=11587) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:45.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:12:45.833+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:45.832+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:45.904+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:45.900+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    create_update_dim_product = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'run_bigquery_sql' has already been added to the DAG
[2024-01-03T17:12:45.905+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:45.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.149 seconds
[2024-01-03T17:12:48.956+0000] {processor.py:157} INFO - Started process (PID=11592) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:48.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:12:48.960+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:48.959+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:49.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:49.291+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:49.291+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:12:49.346+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:49.346+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:12:49.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.427 seconds
[2024-01-03T17:12:51.153+0000] {processor.py:157} INFO - Started process (PID=11597) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:51.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:12:51.157+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:51.156+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:51.237+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:12:51.233+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    create_update_dim_product = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'create_update_dim_product' has already been added to the DAG
[2024-01-03T17:12:51.238+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:12:51.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.133 seconds
[2024-01-03T17:13:21.905+0000] {processor.py:157} INFO - Started process (PID=11629) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:13:21.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:13:21.910+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:13:21.909+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:13:21.955+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:13:21.952+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 79, in <module>
    create_update_dim_product = BigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 1208, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 812, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/task_group.py", line 231, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'create_update_dim_product' has already been added to the DAG
[2024-01-03T17:13:21.956+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:13:21.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.083 seconds
[2024-01-03T17:13:29.317+0000] {processor.py:157} INFO - Started process (PID=11661) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:13:29.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:13:29.321+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:13:29.320+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:13:29.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:13:29.526+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:13:29.526+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:13:29.545+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:13:29.545+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:13:29.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.266 seconds
[2024-01-03T17:13:35.449+0000] {processor.py:157} INFO - Started process (PID=11666) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:13:35.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:13:35.463+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:13:35.462+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:13:35.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:13:35.544+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:13:35.544+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:13:35.572+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:13:35.571+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:13:35.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.157 seconds
[2024-01-03T17:14:06.075+0000] {processor.py:157} INFO - Started process (PID=11698) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:14:06.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:14:06.082+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:14:06.081+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:14:06.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:14:06.245+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:14:06.245+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:14:06.300+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:14:06.300+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:14:06.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.259 seconds
[2024-01-03T17:14:36.806+0000] {processor.py:157} INFO - Started process (PID=11730) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:14:36.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:14:36.810+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:14:36.809+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:14:36.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:14:36.896+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:14:36.895+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:14:36.934+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:14:36.934+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:14:36.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.149 seconds
[2024-01-03T17:14:55.303+0000] {processor.py:157} INFO - Started process (PID=11750) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:14:55.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:14:55.307+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:14:55.306+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:14:55.363+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:14:55.361+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 56, in <module>
    create_update_dim_customer = t1
NameError: name 't1' is not defined
[2024-01-03T17:14:55.363+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:14:55.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.085 seconds
[2024-01-03T17:15:01.742+0000] {processor.py:157} INFO - Started process (PID=11767) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:01.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:01.746+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:01.745+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:01.754+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:01.752+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 56
    t1 =
       ^
SyntaxError: invalid syntax
[2024-01-03T17:15:01.755+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:01.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.057 seconds
[2024-01-03T17:15:04.860+0000] {processor.py:157} INFO - Started process (PID=11772) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:04.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:04.865+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:04.864+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:04.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:04.960+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:04.960+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:15:04.991+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:04.991+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:15:05.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.166 seconds
[2024-01-03T17:15:05.895+0000] {processor.py:157} INFO - Started process (PID=11777) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:05.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:05.898+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:05.898+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:05.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:05.949+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:05.949+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:15:05.966+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:05.966+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:15:05.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.091 seconds
[2024-01-03T17:15:10.001+0000] {processor.py:157} INFO - Started process (PID=11782) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:10.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:10.025+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:10.024+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:10.049+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:10.045+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 68
    t2 =
        ^
SyntaxError: invalid syntax
[2024-01-03T17:15:10.051+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:10.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.107 seconds
[2024-01-03T17:15:13.165+0000] {processor.py:157} INFO - Started process (PID=11787) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:13.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:13.168+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:13.167+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:13.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:13.272+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:13.272+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:15:13.307+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:13.307+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:15:13.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.167 seconds
[2024-01-03T17:15:19.363+0000] {processor.py:157} INFO - Started process (PID=11792) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:19.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:19.367+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:19.366+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:19.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:19.474+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:19.474+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:15:19.497+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:19.497+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:15:19.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.176 seconds
[2024-01-03T17:15:20.449+0000] {processor.py:157} INFO - Started process (PID=11797) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:20.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:20.451+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:20.451+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:20.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:20.501+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:20.501+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:15:20.518+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:20.518+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:15:20.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.088 seconds
[2024-01-03T17:15:24.715+0000] {processor.py:157} INFO - Started process (PID=11802) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:24.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:24.719+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:24.718+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:24.742+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:24.740+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 92
    t4 =
        ^
SyntaxError: invalid syntax
[2024-01-03T17:15:24.744+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:24.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.070 seconds
[2024-01-03T17:15:28.008+0000] {processor.py:157} INFO - Started process (PID=11829) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:28.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:28.013+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:28.012+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:28.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:28.117+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:28.117+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:15:28.154+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:28.153+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:15:28.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.169 seconds
[2024-01-03T17:15:31.116+0000] {processor.py:157} INFO - Started process (PID=11839) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:31.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:15:31.120+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:31.119+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:31.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:15:31.216+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:31.216+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:15:31.241+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:15:31.240+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:15:31.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.147 seconds
[2024-01-03T17:16:00.027+0000] {processor.py:157} INFO - Started process (PID=11866) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:00.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:16:00.033+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:00.033+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:00.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['sql_example']) retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:00.187+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:00.187+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2024-01-03T17:16:00.217+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:00.217+0000] {dag.py:3722} INFO - Setting next_dagrun for sql_example to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T17:16:00.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.233 seconds
[2024-01-03T17:16:11.689+0000] {processor.py:157} INFO - Started process (PID=11876) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:11.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:16:11.693+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:11.693+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:11.702+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:11.700+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 94
    [t1, t2, t3, t4] >>
                       ^
SyntaxError: invalid syntax
[2024-01-03T17:16:11.703+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:11.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.076 seconds
[2024-01-03T17:16:14.789+0000] {processor.py:157} INFO - Started process (PID=11881) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:14.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:16:14.792+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:14.792+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:14.847+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:14.845+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 94, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:16:14.848+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:14.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.093 seconds
[2024-01-03T17:16:15.839+0000] {processor.py:157} INFO - Started process (PID=11886) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:15.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:16:15.842+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:15.842+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:15.879+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:15.878+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:16:15.880+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:15.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.073 seconds
[2024-01-03T17:16:46.816+0000] {processor.py:157} INFO - Started process (PID=11918) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:46.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:16:46.819+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:46.818+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:46.861+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:16:46.859+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:16:46.862+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:16:46.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.080 seconds
[2024-01-03T17:17:17.548+0000] {processor.py:157} INFO - Started process (PID=11950) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:17:17.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:17:17.551+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:17:17.551+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:17:17.612+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:17:17.610+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:17:17.613+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:17:17.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.098 seconds
[2024-01-03T17:17:48.244+0000] {processor.py:157} INFO - Started process (PID=11982) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:17:48.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:17:48.249+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:17:48.248+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:17:48.294+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:17:48.292+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:17:48.295+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:17:48.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.103 seconds
[2024-01-03T17:18:18.844+0000] {processor.py:157} INFO - Started process (PID=12014) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:18:18.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:18:18.847+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:18:18.846+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:18:18.887+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:18:18.884+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:18:18.888+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:18:18.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.102 seconds
[2024-01-03T17:18:49.518+0000] {processor.py:157} INFO - Started process (PID=12046) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:18:49.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:18:49.521+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:18:49.520+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:18:49.589+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:18:49.588+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:18:49.590+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:18:49.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.106 seconds
[2024-01-03T17:19:20.130+0000] {processor.py:157} INFO - Started process (PID=12078) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:19:20.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:19:20.133+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:19:20.133+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:19:20.175+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:19:20.173+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:19:20.176+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:19:20.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.078 seconds
[2024-01-03T17:19:50.887+0000] {processor.py:157} INFO - Started process (PID=12110) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:19:50.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:19:50.890+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:19:50.889+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:19:50.957+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:19:50.955+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:19:50.957+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:19:50.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.103 seconds
[2024-01-03T17:20:21.601+0000] {processor.py:157} INFO - Started process (PID=12142) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:20:21.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:20:21.604+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:20:21.603+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:20:21.668+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:20:21.666+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:20:21.668+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:20:21.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.101 seconds
[2024-01-03T17:20:52.276+0000] {processor.py:157} INFO - Started process (PID=12174) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:20:52.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:20:52.282+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:20:52.280+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:20:52.327+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:20:52.326+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:20:52.328+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:20:52.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.105 seconds
[2024-01-03T17:21:22.881+0000] {processor.py:157} INFO - Started process (PID=12207) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:21:22.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:21:22.884+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:21:22.883+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:21:22.950+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:21:22.948+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:21:22.951+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:21:22.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.110 seconds
[2024-01-03T17:30:13.745+0000] {processor.py:157} INFO - Started process (PID=12239) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:30:13.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:30:13.749+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:30:13.748+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:30:13.813+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:30:13.810+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:30:13.813+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:30:13.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.125 seconds
[2024-01-03T17:30:44.677+0000] {processor.py:157} INFO - Started process (PID=12273) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:30:44.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:30:44.684+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:30:44.683+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:30:44.755+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:30:44.753+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:30:44.756+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:30:44.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.123 seconds
[2024-01-03T17:31:15.437+0000] {processor.py:157} INFO - Started process (PID=12305) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:31:15.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:31:15.441+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:31:15.440+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:31:15.499+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:31:15.498+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:31:15.500+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:31:15.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.091 seconds
[2024-01-03T17:31:46.063+0000] {processor.py:157} INFO - Started process (PID=12337) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:31:46.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:31:46.069+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:31:46.068+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:31:46.112+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:31:46.110+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:31:46.112+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:31:46.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.112 seconds
[2024-01-03T17:32:16.730+0000] {processor.py:157} INFO - Started process (PID=12369) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:32:16.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:32:16.733+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:32:16.733+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:32:16.776+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:32:16.774+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:32:16.776+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:32:16.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.098 seconds
[2024-01-03T17:32:47.358+0000] {processor.py:157} INFO - Started process (PID=12401) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:32:47.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:32:47.362+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:32:47.361+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:32:47.422+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:32:47.421+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    [t1, t2, t3, t4] >> t5
NameError: name 't5' is not defined
[2024-01-03T17:32:47.423+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:32:47.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.093 seconds
[2024-01-03T17:33:06.886+0000] {processor.py:157} INFO - Started process (PID=12433) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:06.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:06.889+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:06.889+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:06.936+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:06.934+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    python_callable=train_model,
NameError: name 'train_model' is not defined
[2024-01-03T17:33:06.937+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:06.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.092 seconds
[2024-01-03T17:33:11.044+0000] {processor.py:157} INFO - Started process (PID=12438) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:11.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:11.047+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:11.046+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:11.058+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:11.056+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 99
    t5 =
        ^
SyntaxError: invalid syntax
[2024-01-03T17:33:11.059+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:11.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.078 seconds
[2024-01-03T17:33:14.184+0000] {processor.py:157} INFO - Started process (PID=12443) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:14.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:14.188+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:14.187+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:14.250+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:14.248+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    python_callable=train_model,
NameError: name 'train_model' is not defined
[2024-01-03T17:33:14.250+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:14.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.101 seconds
[2024-01-03T17:33:15.240+0000] {processor.py:157} INFO - Started process (PID=12448) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:15.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:15.243+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:15.242+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:15.271+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:15.270+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 96, in <module>
    python_callable=train_model,
NameError: name 'train_model' is not defined
[2024-01-03T17:33:15.272+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:15.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.062 seconds
[2024-01-03T17:33:25.684+0000] {processor.py:157} INFO - Started process (PID=12480) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:25.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:25.691+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:25.690+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:25.751+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:25.749+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 98, in <module>
    python_callable=train_model,
NameError: name 'train_model' is not defined
[2024-01-03T17:33:25.752+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:25.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.102 seconds
[2024-01-03T17:33:29.820+0000] {processor.py:157} INFO - Started process (PID=12485) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:29.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:29.824+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:29.823+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:29.833+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:29.831+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 94
    def train_model()
                    ^
SyntaxError: invalid syntax
[2024-01-03T17:33:29.834+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:29.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.051 seconds
[2024-01-03T17:33:31.903+0000] {processor.py:157} INFO - Started process (PID=12490) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:31.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:31.908+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:31.908+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:31.914+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:31.913+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 97
    train_model = PythonOperator(
    ^
IndentationError: expected an indented block
[2024-01-03T17:33:31.914+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:31.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.044 seconds
[2024-01-03T17:33:35.034+0000] {processor.py:157} INFO - Started process (PID=12495) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:35.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:35.038+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:35.037+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:35.047+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:35.045+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9
    import
          ^
SyntaxError: invalid syntax
[2024-01-03T17:33:35.048+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:35.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.074 seconds
[2024-01-03T17:33:40.186+0000] {processor.py:157} INFO - Started process (PID=12500) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:40.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:40.190+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:40.190+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:40.200+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:40.198+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 97
    train_model = PythonOperator(
    ^
IndentationError: expected an indented block
[2024-01-03T17:33:40.201+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:40.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.055 seconds
[2024-01-03T17:33:48.347+0000] {processor.py:157} INFO - Started process (PID=12505) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:48.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:33:48.350+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:48.350+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:48.365+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:33:48.356+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9
    from clustering
                  ^
SyntaxError: invalid syntax
[2024-01-03T17:33:48.367+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:33:48.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.065 seconds
[2024-01-03T17:34:19.148+0000] {processor.py:157} INFO - Started process (PID=12537) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:34:19.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:34:19.152+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:34:19.152+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:34:19.171+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:34:19.168+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9
    from clustering
                  ^
SyntaxError: invalid syntax
[2024-01-03T17:34:19.172+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:34:19.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.065 seconds
[2024-01-03T17:34:49.770+0000] {processor.py:157} INFO - Started process (PID=12575) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:34:49.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:34:49.775+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:34:49.774+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:34:49.785+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:34:49.783+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9
    from clustering
                  ^
SyntaxError: invalid syntax
[2024-01-03T17:34:49.786+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:34:49.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.059 seconds
[2024-01-03T17:35:20.545+0000] {processor.py:157} INFO - Started process (PID=12608) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:20.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:35:20.549+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:20.548+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:20.557+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:20.556+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9
    from clustering
                  ^
SyntaxError: invalid syntax
[2024-01-03T17:35:20.558+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:20.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.067 seconds
[2024-01-03T17:35:33.939+0000] {processor.py:157} INFO - Started process (PID=12633) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:33.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:35:33.943+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:33.942+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:33.953+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:33.951+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 97
    train_model = PythonOperator(
    ^
IndentationError: expected an indented block
[2024-01-03T17:35:33.953+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:34.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.089 seconds
[2024-01-03T17:35:41.084+0000] {processor.py:157} INFO - Started process (PID=12638) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:41.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:35:41.089+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:41.088+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:41.116+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:41.111+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 94
    def ():
        ^
SyntaxError: invalid syntax
[2024-01-03T17:35:41.117+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:41.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.069 seconds
[2024-01-03T17:35:48.357+0000] {processor.py:157} INFO - Started process (PID=12643) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:48.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:35:48.361+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:48.360+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:48.371+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:48.369+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 97
    train_model = PythonOperator(
    ^
IndentationError: expected an indented block
[2024-01-03T17:35:48.372+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:48.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.060 seconds
[2024-01-03T17:35:51.459+0000] {processor.py:157} INFO - Started process (PID=12655) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:51.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:35:51.463+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:51.462+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:51.524+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:35:51.521+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:35:51.525+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:35:51.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.108 seconds
[2024-01-03T17:36:00.917+0000] {processor.py:157} INFO - Started process (PID=12680) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:00.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:36:00.921+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:36:00.920+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:00.970+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:36:00.968+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:36:00.971+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:00.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.088 seconds
[2024-01-03T17:36:28.699+0000] {processor.py:157} INFO - Started process (PID=12712) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:28.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:36:28.702+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:36:28.702+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:28.787+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:36:28.780+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:36:28.789+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:28.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.141 seconds
[2024-01-03T17:36:31.797+0000] {processor.py:157} INFO - Started process (PID=12717) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:31.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:36:31.803+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:36:31.802+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:31.960+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:36:31.941+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:36:31.961+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:32.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.286 seconds
[2024-01-03T17:36:40.523+0000] {processor.py:157} INFO - Started process (PID=12722) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:40.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:36:40.527+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:36:40.526+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:40.575+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:36:40.573+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:36:40.576+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:36:40.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.122 seconds
[2024-01-03T17:37:11.209+0000] {processor.py:157} INFO - Started process (PID=12754) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:37:11.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:37:11.213+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:37:11.213+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:37:11.252+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:37:11.247+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:37:11.253+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:37:11.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.076 seconds
[2024-01-03T17:37:41.818+0000] {processor.py:157} INFO - Started process (PID=12786) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:37:41.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:37:41.821+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:37:41.820+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:37:41.850+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:37:41.848+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:37:41.851+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:37:41.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.076 seconds
[2024-01-03T17:38:12.549+0000] {processor.py:157} INFO - Started process (PID=12818) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:38:12.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:38:12.554+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:38:12.553+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:38:12.594+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:38:12.591+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:38:12.594+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:38:12.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.085 seconds
[2024-01-03T17:38:43.190+0000] {processor.py:157} INFO - Started process (PID=12850) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:38:43.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:38:43.193+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:38:43.193+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:38:43.219+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:38:43.217+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:38:43.220+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:38:43.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.065 seconds
[2024-01-03T17:39:14.224+0000] {processor.py:157} INFO - Started process (PID=12882) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:39:14.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:39:14.253+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:39:14.252+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:39:14.395+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:39:14.386+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:39:14.397+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:39:14.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.276 seconds
[2024-01-03T17:39:45.292+0000] {processor.py:157} INFO - Started process (PID=12914) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:39:45.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:39:45.296+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:39:45.295+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:39:45.325+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:39:45.323+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:39:45.326+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:39:45.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.083 seconds
[2024-01-03T17:40:16.047+0000] {processor.py:157} INFO - Started process (PID=12947) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:40:16.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:40:16.051+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:40:16.050+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:40:16.106+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:40:16.103+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:40:16.107+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:40:16.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.106 seconds
[2024-01-03T17:40:46.878+0000] {processor.py:157} INFO - Started process (PID=12979) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:40:46.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:40:46.882+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:40:46.881+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:40:46.916+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:40:46.914+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:40:46.917+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:40:46.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.088 seconds
[2024-01-03T17:41:17.562+0000] {processor.py:157} INFO - Started process (PID=13012) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:41:17.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:41:17.566+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:41:17.566+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:41:17.602+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:41:17.599+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:41:17.602+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:41:17.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.079 seconds
[2024-01-03T17:41:48.226+0000] {processor.py:157} INFO - Started process (PID=13044) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:41:48.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:41:48.231+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:41:48.230+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:41:48.263+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:41:48.261+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:41:48.263+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:41:48.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.092 seconds
[2024-01-03T17:42:18.887+0000] {processor.py:157} INFO - Started process (PID=13077) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:42:18.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:42:18.890+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:42:18.890+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:42:18.923+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:42:18.921+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:42:18.924+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:42:18.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.084 seconds
[2024-01-03T17:42:49.525+0000] {processor.py:157} INFO - Started process (PID=13109) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:42:49.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:42:49.528+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:42:49.527+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:42:49.577+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:42:49.575+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:42:49.578+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:42:49.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.091 seconds
[2024-01-03T17:43:20.282+0000] {processor.py:157} INFO - Started process (PID=13141) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:43:20.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:43:20.287+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:43:20.286+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:43:20.336+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:43:20.333+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:43:20.337+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:43:20.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.099 seconds
[2024-01-03T17:43:51.099+0000] {processor.py:157} INFO - Started process (PID=13173) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:43:51.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:43:51.104+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:43:51.103+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:43:51.141+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:43:51.139+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:43:51.142+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:43:51.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.097 seconds
[2024-01-03T17:44:21.901+0000] {processor.py:157} INFO - Started process (PID=13205) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:44:21.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:44:21.909+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:44:21.908+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:44:21.949+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:44:21.947+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:44:21.950+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:44:21.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.097 seconds
[2024-01-03T17:44:52.598+0000] {processor.py:157} INFO - Started process (PID=13244) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:44:52.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:44:52.602+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:44:52.601+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:44:52.634+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:44:52.632+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:44:52.635+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:44:52.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.089 seconds
[2024-01-03T17:45:23.325+0000] {processor.py:157} INFO - Started process (PID=13276) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:45:23.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:45:23.329+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:45:23.328+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:45:23.387+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:45:23.385+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:45:23.388+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:45:23.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.096 seconds
[2024-01-03T17:45:54.019+0000] {processor.py:157} INFO - Started process (PID=13308) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:45:54.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:45:54.024+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:45:54.023+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:45:54.061+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:45:54.059+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:45:54.062+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:45:54.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.078 seconds
[2024-01-03T17:46:24.845+0000] {processor.py:157} INFO - Started process (PID=13340) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:46:24.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:46:24.848+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:46:24.847+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:46:24.877+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:46:24.875+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:46:24.878+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:46:24.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.060 seconds
[2024-01-03T17:47:34.297+0000] {processor.py:157} INFO - Started process (PID=168) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:47:34.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:47:34.315+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:47:34.314+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:47:34.484+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:47:34.476+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:47:34.485+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:47:34.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.233 seconds
[2024-01-03T17:48:05.096+0000] {processor.py:157} INFO - Started process (PID=201) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:48:05.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:48:05.105+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:48:05.104+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:48:05.197+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:48:05.192+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:48:05.198+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:48:05.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.156 seconds
[2024-01-03T17:48:26.758+0000] {processor.py:157} INFO - Started process (PID=233) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:48:26.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:48:26.778+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:48:26.778+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:48:26.818+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:48:26.816+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:48:26.818+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:48:26.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.106 seconds
[2024-01-03T17:48:57.424+0000] {processor.py:157} INFO - Started process (PID=265) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:48:57.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:48:57.430+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:48:57.430+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:48:57.464+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:48:57.462+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:48:57.465+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:48:57.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.082 seconds
[2024-01-03T17:49:28.115+0000] {processor.py:157} INFO - Started process (PID=297) to work on /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:49:28.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/data_transform_BQ.py for tasks to queue
[2024-01-03T17:49:28.122+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:49:28.122+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:49:28.150+0000] {logging_mixin.py:154} INFO - [2024-01-03T17:49:28.147+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/data_transform_BQ.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/data_transform_BQ.py", line 9, in <module>
    from clustering import train_model
  File "/opt/airflow/dags/clustering.py", line 4, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
[2024-01-03T17:49:28.150+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/data_transform_BQ.py
[2024-01-03T17:49:28.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/data_transform_BQ.py took 0.090 seconds
